{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Multivariate Statistik und Machine Learning: Assignment 1\n",
    "\n",
    "The exercises on this sheet are graded by a maximum of 10 points. You will be asked to implement several functions.\n",
    "\n",
    "Team work is not allowed. Everybody implements his/her own code. Discussing issues with others is fine, sharing code with others is not. \n",
    "\n",
    "do we need this? -> If you use any code fragments found on the Internet, make sure you reference them properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 -- Multivariate normal distribution  (4 Points)\n",
    "\n",
    "We know from the Lecture 2, the probability density function for multivariate normal is:\n",
    "\n",
    "$f(x) = \\frac{1}{\\sqrt{(2 \\pi)^d \\det \\Sigma}} \\exp\\left( -\\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu) \\right) ,$ \n",
    "    \n",
    "where $\\mu$ is the mean, $\\Sigma$ the covariance matrix, and $d$ is the dimension of the space where $x$ takes values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Implement function `multivariate_normal` that computes the probability of a point $x$ from the mean vector and the covariance matrix. Visualize then the following two bivariate normal distributions: \n",
    "\n",
    "(i) $ \\mu_1 =  \n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "0\n",
    "\\end{bmatrix}, \\Sigma_1 =  \n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 2\n",
    "\\end{bmatrix} $\n",
    "\n",
    "(ii) $ \\mu_2 = \n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "-1\n",
    "\\end{bmatrix},\n",
    "\\Sigma_2 =  \n",
    "\\begin{bmatrix}\n",
    "9 & -2.5 \\\\\n",
    "-2.5 & 1 \n",
    "\\end{bmatrix} $\n",
    "\n",
    "You cannot use already implemented functions for `multivariate_normal` in python libraries but you can test if your implementation is correct using `scipy.stats.multivariate_normal`. \n",
    "Other helpful functions that you might need: `numpy.linalg`, `numpy.ndarray.T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import scipy.stats\n",
    "%matplotlib inline\n",
    "\n",
    "mu_1 = np.array([1,0])\n",
    "cov_1 = np.array([[1,0],[0,2]])\n",
    "\n",
    "mu_2 = np.array([0,-1])\n",
    "cov_2 = np.array([[9,-2.5],[-2.5,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal(x,mean, covariance):\n",
    "    \"\"\"pdf of the multivariate normal distribution.\"\"\"\n",
    "    p = ... \n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the two normal distribution\n",
    "plot_2d_normal(mu_1,cov_1,multivariate_normal)\n",
    "plot_2d_normal(mu_2,cov_2,multivariate_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Implement a function `marginalize_multivariate_normal` which receives as input the mean vector and the covariance matrix of a multivariate normal distribution, and the index of the dimension over which we want to compute the marginal distribution; it returns the mean and the variance of the univariate marginal distribution. Implement the function `univariate_normal` that computes the probability of a univariate normal distribution. Get the mean and variance for dimension 0 marginal of normal distribution $1$, and for dimension 1 marginal of normal distribution $2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginalize_multivariate_normal(mean,cov):\n",
    "    \"\"\"extract univariate normal distribution for dimension dim\"\"\"\n",
    "\n",
    "    mean_univariate = ...\n",
    "    var = ...\n",
    "    \n",
    "    return mean_univariate,var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_normal(x, mean, variance):\n",
    "    \"\"\"pdf of the univariate normal distribution.\"\"\"\n",
    "    \n",
    "    p = ...\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_1_marginal, var_1_marginal = marginalize_multivariate_normal(mu_1,cov_1,0)\n",
    "mu_2_marginal, var_2_marginal = marginalize_multivariate_normal(mu_2,cov_2,1)\n",
    "\n",
    "plot_1d_normal(mu_1_marginal,var_1_marginal,univariate_normal)\n",
    "plot_1d_normal(mu_2_marginal,var_2_marginal,univariate_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 One way to view a gaussian distribution in 2D is using contour plot. In the following figure, we can see the contour plots of distributions with covariance and mean written below. Please complete the following cell and match the figures with correct values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"h.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance matrices:\n",
    "\n",
    "1. $ \\Big( \\begin{bmatrix}\n",
    "1 & 0.8 \\\\\n",
    "0.8 & 1 \n",
    "\\end{bmatrix}\\Big) $\n",
    "2. $ \\Big( \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1 \n",
    "\\end{bmatrix}\\Big) $\n",
    "3. $ \\Big( \\begin{bmatrix}\n",
    "1 & 0.8 \\\\\n",
    "0.8 & 3 \n",
    "\\end{bmatrix}\\Big) $\n",
    "4. $ \\Big( \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 3.5 \n",
    "\\end{bmatrix}\\Big) $\n",
    "5. $ \\Big( \\begin{bmatrix}\n",
    "3 & 0.8 \\\\\n",
    "0.8 & 1 \n",
    "\\end{bmatrix}\\Big) $\n",
    "6. $ \\Big( \\begin{bmatrix}\n",
    "1 & -1 \\\\\n",
    "-1 & 3 \n",
    "\\end{bmatrix}\\Big) $\n",
    "7. $ \\Big( \\begin{bmatrix}\n",
    "3 & -1 \\\\\n",
    "-1 & 1 \n",
    "\\end{bmatrix}\\Big) $\n",
    "8. $ \\Big( \\begin{bmatrix}\n",
    "1 & -1.5 \\\\\n",
    "-1.5 & 3 \n",
    "\\end{bmatrix}\\Big) $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which image corresponds to which covariance matrix? (hint: use the function implemented above to visualize the different multivariate distributions):\n",
    "\n",
    "1 -\n",
    "\n",
    "2 -\n",
    "\n",
    "3 -\n",
    "\n",
    "4 -\n",
    "\n",
    "5 -\n",
    "\n",
    "6 -\n",
    "\n",
    "7 -\n",
    "\n",
    "8 -\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 --  EMD and KL Divergence (2 Points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suppose we have two discrete distributions $P$ and $Q$ with the following probability mass functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([4,2,1,5,8,2,3,1,2,2])/30.\n",
    "Q = np.array([1,8,3,6,4,2,1,3,1,1])/30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 write the functions `EMD` and `KL_div` which receive as input two discrete distributions and compute the EMD and the KL divergence between the two (see course slides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KL Divergence implementation\n",
    "def KL_div(P, Q):\n",
    "    \n",
    "    kl_div = ...\n",
    "    \n",
    "    return kl_div "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMD implementation\n",
    "def emd(P,Q):\n",
    "    \n",
    "    emd_dis = ...\n",
    "        \n",
    "    return emd_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emd(P,Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(KL_div(P,Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 -- t-student test (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Assume you obtain three different samples coming from three normal distributions:\n",
    "\n",
    "$P_a \\sim X_a, P_b \\sim X_b,P_c \\sim X_c$.\n",
    "\n",
    "\n",
    "We will perform a two-sample test to compare if the mean between pairs of samples is the same or not. This can be done with the $t$ statistic. We further more assume we have the same number of samples from each sample $N= N_a = N_b = N_c$:\n",
    "\n",
    "$ t = \\dfrac{\\bar{x_a} - \\bar{x_a}}\n",
    "          {s\\sqrt{\\dfrac{2}{N}}} $\n",
    "\n",
    "where the $s = \\sqrt{\\dfrac{(N-1)({s_a}^2 + {s_b}^2)}{2N-2}}$ and $s_a$ and $s_b$ are the sample variances.\n",
    "\n",
    "Our goal is to use this test to see in which of the following cases we can identify wheter 2 samples have the same mean or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. write down the null-hypothesis that we assume to use the t-statistic (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0 = .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will rely on the `np.random.normal` function to create a function that returns $N$ samples given a $\\mu$ and $\\sigma$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(N):\n",
    "    X1 = np.random.normal(1,1,N)\n",
    "    X2 = np.random.normal(1.25,1,N)\n",
    "    X3 = np.random.normal(2.,1,N)\n",
    "    \n",
    "    return (X1,X2,X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa, Xb, Xc = get_samples(N=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Â 3.2 Complete the `compute_t_statistic` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_t_statistic(x1,x2):\n",
    "    \n",
    "    n = x1.shape[0]\n",
    "    assert x1.shape[0] == x2.shape[0]\n",
    "    # compute sample mean and variances\n",
    "   \n",
    "    \n",
    "    # first we compute the sample variances\n",
    "\n",
    "    \n",
    "    # compute the standard deviation of the differnce\n",
    "    \n",
    "    t = ...\n",
    "    \n",
    "    return t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_means(X1,X2):\n",
    "    \n",
    "    t = compute_t_statistic(X1,X2)\n",
    "    \n",
    "    p = ... # p-value --- yout might want to use scipy.stats.t, and remember to take into account both tails...\n",
    "    \n",
    "    return t, p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `t_test_means` to compute the comparison between each pair: \n",
    "\n",
    "A vs B, A vs C, B vs C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = t_test_means(Xb,Xa)\n",
    "print(f't-statistic: {t:.3f}, p-value:{p:.2} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = t_test_means(Xa,Xc)\n",
    "print(f't-statistic: {t:.3f}, p-value:{p:.2} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = t_test_means(Xb,Xc)\n",
    "print(f't-statistic: {t:.3f}, p-value:{p:.2e} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you can check the results of your implemenetation with the following scipy function\n",
    "t, p = scipy.stats.ttest_ind(Xa,Xa)\n",
    "print(f't-statistic: {t:.3f}, p-value:{p:.2e} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Now test different sample sizes and see how many samples do we need for the test to distinguish between the different pairs? which one is the easiest to distinguish? which the hardest? \n",
    "hint: use the plot to support your analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = [1e1,5e1,1e2,5e2,1e3,5e3,1e4,5e4,1e5,5e5,1e6]\n",
    "results = np.ones((3,len(n_list)))\n",
    "\n",
    "for id_, n in enumerate(n_list):\n",
    "    n = int(n)\n",
    "    Xa, Xb, Xc = get_samples(N=n)\n",
    "    \n",
    "    _, p = t_test_means(Xa,Xb)\n",
    "    results[0,id_] = p\n",
    "    \n",
    "    _, p = t_test_means(Xa,Xc)\n",
    "    results[1,id_] = p\n",
    "    _, p = t_test_means(Xc,Xb)\n",
    "    results[2,id_] = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#log_p_values = np.log(results+1e-12)\n",
    "log_p_values = results\n",
    "ax.plot(n_list,log_p_values[0], label='A-B')\n",
    "ax.plot(n_list,log_p_values[1], label='A-C')\n",
    "ax.plot(n_list,log_p_values[2], label='B-C')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"# samples\")\n",
    "ax.set_ylabel(\"p-value\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
