{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Statistik und Machine Learning: Assignment 6\n",
    "In this exercise you will learn how to use neural networs in simulated and real datasets.\n",
    "\n",
    "Please note it is important to answer questions when they are given, as we will reduce points in case no specific answer is given.\n",
    "\n",
    "For this we will use the [Pytorch](https://pytorch.org) library. You can install pytorch using`conda` environment or `pip` (see pytorch website).\n",
    "you will also need `conda install -c pytorch torchvision`\n",
    "\n",
    "__Team work is not allowed__. Everybody implements his/her own code. Discussing issues with others is fine, sharing code and/or answers with others is __not__. If you use any code fragments found on the Internet, make sure you reference them properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1, 1pt\n",
    "\n",
    "In this first exercise we are going to get an idea on how simple neural networks\n",
    "behave for simple classification tasks. We’ll make use of two different javascript\n",
    "based neural network to train and modify an existing model. Let’s start with a very\n",
    "simple one, a simple neural network with only fully connected layers and without\n",
    "convolutions. Open a web browser on the page http://playground.tensorflow.org/ and start playing with the interface. For each dataset set the noise level to 30. Click play on the top-left to start training. To assess the quality of the network look at the values train and test loss at the top right. Tip: Sometimes it’s easier\n",
    "to see the result if you discretise the graph.\n",
    "\n",
    "\n",
    "1. For the spiral dataset try to design the best architecture you can to solve the problem.\n",
    "\n",
    "To get the point in this task you need to add a screenshot to the submission zip file with the best architecture and answer the following:\n",
    "\n",
    "- Now try to find an architecture that is as small as possible (low number of layers, low number of neurons), With a smaller architecture, can you keep a similar performance? You can support your answer with the test-loss numbers from the test set. \n",
    "- In the spiral dataset, do you observe any advantages of having a deep network (more layers) than a wider network (more neurons per layer)? Which one performs better in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "#### Yes, the smallest architecture with the best performance I could found was 3 hidden layers and with (8 neurons,8 neurons, 1 neuron) --> the criteria for the best performance was the robustness of this noisy data (noise = 30) in aspect to the test loss. the test loss was more or less constant around ~0.02 (which was also the smallest) with different regenerated data\n",
    "#### Deeper Networks seem to converge faster and tend to less overdit but on my opinion wider networks work better in this case because the test loss seems to be lower in general in this situation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The following part is optional, but fun!__ Open this page https://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html and try to tweak all the parameters you can to obtain the best network (the highest validation accuracy).\n",
    "Scroll down the page and peek inside the network and have a look at different\n",
    "activation and weight as the network gets trained (click pause to make it freeze).\n",
    "Check how the prediction works on the test set in the last part of the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 Backpropagation, 3 pts\n",
    "\n",
    "As you saw in the lecture neural networks are just a stack of simple functions, interlayered with non-linearity functions to model complex problems. Everything must be differentiable to use convex optimizers. For any of such optmizers, we need to compute gradients from the output of the network with respect to the input. Which can be easily computed using the chain rule. \n",
    "\n",
    "Let our neural network be defined by the function $f(x) = h_1(h_2(h_3(x)))$.\n",
    "\n",
    "Using the chain rule we can compute \n",
    "\n",
    "\n",
    "$$ \\dfrac{\\partial f}{\\partial x} = \\dfrac{\\partial h_1}{\\partial h_2} \\dfrac{\\partial h_2}{\\partial x} $$\n",
    "\n",
    "$$ \\dfrac{\\partial f}{\\partial x} = \\dfrac{\\partial h_1}{\\partial h_2} \\dfrac{\\partial h_2}{\\partial h_3}  \\dfrac{\\partial h_3}{\\partial x}$$\n",
    "\n",
    "\n",
    "let $h_1$ and $h_3$ be linear layer of the form $h_1(x) = w_1*x$ and $h_3(x) = 2*w_3*x+b_3+1$. For simplicity we will use an identity instead of a nonlinearity like ReLU or tanh.\n",
    "\n",
    "\n",
    "#### Ex.3.1 Write down the partial derivatives of $h_1$ and $h_3$.\n",
    "\n",
    "This should be done with respect to the input and each of the parameters ($x, w_1, w_3, b_3$). Here we ask you for the formula not the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\dfrac{\\partial h_1}{\\partial x} = w_1 $$\n",
    "$$ \\dfrac{\\partial h_1}{\\partial w_1} = x $$\n",
    "$$ \\dfrac{\\partial h_3}{\\partial x} = 2 \\cdot w_3 $$\n",
    "$$ \\dfrac{\\partial h_3}{\\partial w_3} = 2 \\cdot x $$\n",
    "$$ \\dfrac{\\partial h_3}{\\partial b_3} = 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such linear layers are already implemented in most common frameworks. And have automated gradient computation. In Pytorch this is called [Autograd](https://pytorch.org/docs/stable/autograd.html). In pytorch a linear function is defined in the `torch.nn.Linear` class.\n",
    "\n",
    "Which means all the derivatives $\\dfrac{\\partial h_1}{\\partial x}$ and $\\dfrac{\\partial h_3}{\\partial x}$ are computed automatically with autograd.\n",
    "\n",
    "The following code is an example implementation of a Linear function ([see source](https://pytorch.org/docs/stable/notes/extending.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Inherit from Function\n",
    "class LinearFunction(torch.autograd.Function):\n",
    "\n",
    "    # Note that both forward and backward are @staticmethods\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias=None):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        output = input.mm(weight.t())\n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "        return output\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # This is a pattern that is very convenient - at the top of backward\n",
    "        # unpack saved_tensors and initialize all gradients w.r.t. inputs to\n",
    "        # None. Thanks to the fact that additional trailing Nones are\n",
    "        # ignored, the return statement is simple even when the function has\n",
    "        # optional inputs.\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "\n",
    "        # These needs_input_grad checks are optional and there only to\n",
    "        # improve efficiency. If you want to make your code simpler, you can\n",
    "        # skip them. Returning gradients for inputs that don't require it is\n",
    "        # not an error.\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            # df/dx = w\n",
    "            grad_input = grad_output.mm(weight)\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            # df/dw = x\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            # df/fb = 1\n",
    "            grad_bias = grad_output.sum(0)\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias\n",
    "    \n",
    "linear = LinearFunction.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 20\n",
    "in_dim = 20\n",
    "out_dim = 30\n",
    "\n",
    "input = (torch.randn(batch,in_dim,dtype=torch.double,requires_grad=True), # input data\n",
    "         torch.randn(out_dim,in_dim,dtype=torch.double,requires_grad=True),\n",
    "         torch.randn(out_dim,dtype=torch.double,requires_grad=True), # bias\n",
    "        )\n",
    "test = torch.autograd.gradcheck(linear, input, eps=1e-6, atol=1e-4)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex.2.2 Implement $h_2(x)$ in pytorch.\n",
    "\n",
    "\n",
    "Stacking linear functions with non-linearities creates powerful networks to tackle complex tasks. Some times however more complicaded functions are most fitted to certain settings (e.g. physical constrains, optimization constrains, etc.). Which is why we may need to implement a more complex function in a single layer.\n",
    "\n",
    "Let $h_2$ has the form:\n",
    "\n",
    "$$h_2(x) =  w_{21}*x + w_{22}*x^2 +exp(w_{23}*x)+b_2$$\n",
    "\n",
    "\n",
    "Use the MyFunction class skeleton below. You need to:\n",
    "- write the forward pass (i.e. feed the inputs through the function using the function's parameters)\n",
    "- write your own implementation of the backward pass (i.e. compute $\\dfrac{\\partial h_2}{\\partial x}$ and return the product with the previous gradient. In our example the `grad_output` would be equivalent to $\\dfrac{\\partial h_1}{\\partial h_2}$ and the function should return the product of `grad_output` and the gradients with respect to each of the inputs \n",
    "$(\\dfrac{\\partial h_1}{\\partial h_2}\\dfrac{\\partial h_2}{\\partial x},\n",
    "  \\dfrac{\\partial h_1}{\\partial h_2}\\dfrac{\\partial h_2}{\\partial w_{21}},\n",
    "  \\dfrac{\\partial h_1}{\\partial h_2}\\dfrac{\\partial h_2}{\\partial w_{22}},...)$. \n",
    "\n",
    "Note that you need to return gradients with respect to each of the inputs involved in $h_2$ in the same order the were recieved in the forward pass ($x, w_{21},w_{22},w_{23},b_{21}$).\n",
    "\n",
    "For simplicity, asume that the input is in $\\mathbb{R}^1$ and the function only outputs a single scalar. It must however be able to recieve batches of samples with the shape (batch, 1).\n",
    "\n",
    "\n",
    "Hints:\n",
    "\n",
    "- First write down the formulas of each of the partial derivatives, and then implement them. This should facilitate the writing of the code.\n",
    "- `tensor_x.t()` denotes transpose of tensor_x\n",
    "- for a matrix multiplication between x and y use `x.mm(y)`.\n",
    "- for basic operations you can use:  `tensor_a.sum(tensor_b)` ,  `tensor_a.mul(tensor_b)`,`tensor_a.pow(2)`, `torch.exp(x)` ,  etc. ([see more](https://pytorch.org/docs/stable/tensors.html))\n",
    "- it is important that the function returns pytorch tensors types.\n",
    "- in case you need to create new tensors, make sure they are of type `double`, this is necessarily to make the gradcheck function work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFunction(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, w21, w22=None, w23=None, b2=None):\n",
    "        ctx.save_for_backward(input, w21,w22,w23,b2)\n",
    "        \n",
    "        output = w21*input ##\n",
    "        if w22 is not None:\n",
    "            output += w22*input.pow(2)##\n",
    "        if w23 is not None:\n",
    "            output += torch.exp(w23*input)##\n",
    "        if b2 is not None:\n",
    "            output += b2##\n",
    "                 \n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # This is a pattern that is very convenient - at the top of backward\n",
    "        # unpack saved_tensors and initialize all gradients w.r.t. inputs to\n",
    "        # None. Thanks to the fact that additional trailing Nones are\n",
    "        # ignored, the return statement is simple even when the function has\n",
    "        # optional inputs.\n",
    "        input, w21, w22, w23, b2 = ctx.saved_tensors\n",
    "\n",
    "        \n",
    "        grad_input = grad_w21 = grad_w22 = grad_w23 = grad_b2 = None\n",
    "        print(grad_output.size())\n",
    "        grad_input = w21*grad_output\n",
    "        \n",
    "        \n",
    "        if w22 is not None:\n",
    "            grad_input += w22*2*input\n",
    "        if w23 is not None:\n",
    "            #grad_input += torch.exp(input*w23)*w23\n",
    "        \n",
    "        \n",
    "        \n",
    "        if w22 is not None and ctx.needs_input_grad[2]:\n",
    "            grad_input += w22*2*input*grad_output\n",
    "            grad_w22 = input.pow(2)*grad_output\n",
    "            \n",
    "        if w23 is not None and ctx.needs_input_grad[3]:\n",
    "            grad_input += torch.exp(input*w23)*w23*grad_output\n",
    "            grad_w23 = x*torch.exp(w23*input)*input*grad_output\n",
    "        if b2 is not None and ctx.needs_input_grad[4]:\n",
    "            grad_b2 = grad_output\n",
    "        \n",
    "        return grad_input, grad_w21, grad_w22, grad_w23, grad_b2\n",
    "myfunction = MyFunction.apply   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code below you can test your implementation `gradcheck`performs a numerical computation of the gradient to verify that the analytical solution we wrote is correct.\n",
    "\n",
    "You omit some parameters to test the gradients one by one. For example: (input, w21) will compute and check only the gradients where w21 is involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2\n",
    "d_in = 1\n",
    "d_out = 1\n",
    "input_test = (torch.randn(batch,d_in,dtype=torch.double,requires_grad=True), # input\n",
    "         torch.randn(d_out,d_in,dtype=torch.double,requires_grad=True), # w21\n",
    "         torch.randn(d_out,d_in,dtype=torch.double,requires_grad=False), # w22\n",
    "         #torch.randn(d_out,d_in,dtype=torch.double,requires_grad=True), # w23\n",
    "         #torch.randn(d_out,dtype=torch.double,requires_grad=True) # b21\n",
    "             )\n",
    "\n",
    "res = torch.autograd.gradcheck(myfunction, input_test, raise_exception=False)\n",
    "print(res) # res should be True if the gradients are correct.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of implentation of a pytorch module using the function we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H2(nn.Module):\n",
    "    def __init__(self, input_features, output_features, is_example=False):\n",
    "        # input_features define the dimension of the input\n",
    "        # output_features defines the dimensions of the output\n",
    "        \n",
    "        super(H2, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.output_features = output_features\n",
    "        \n",
    "        \n",
    "        self.w21 = nn.Parameter(torch.Tensor(output_features, input_features))\n",
    "        self.w21.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "        if is_example:\n",
    "            self.w22 = nn.Parameter(torch.Tensor(output_features, input_features))\n",
    "            self.w23 = nn.Parameter(torch.Tensor(output_features, input_features))\n",
    "            self.b2 = nn.Parameter(torch.Tensor(output_features))\n",
    "        \n",
    "            self.w22.data.uniform_(-0.1, 0.1)\n",
    "            self.w23.data.uniform_(-0.1, 0.1)\n",
    "            self.b2.data.uniform_(-0.1, 0.1)\n",
    "        else:\n",
    "            self.w22 = None\n",
    "            self.w23 = None\n",
    "            self.b2 = None\n",
    "            \n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        output = myfunction(input, self.w21,self.w22,self.w23, self.b2)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = H2(input_features=1,output_features=1, is_example=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3,1)\n",
    "x_out = h2(x)\n",
    "\n",
    "dummy_loss = x_out.sum()\n",
    "dummy_loss.backward()\n",
    "print(dummy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3, 3pts\n",
    "\n",
    "In this exercise you have to train a new Convolutional Neural Network from scratch for the classification of images. The aim is to achieve a high score (98%-99% accuracy on the test set) on the MNIST dataset http://yann.lecun.com/exdb/mnist/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.utils.data as datatorch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import sys\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "##if 'ipykernel' in sys.modules: <--- this statement causes an error\n",
    "    ##import tqdm as tqdm_lib\n",
    "    ##tqdm = tqdm_lib.notebook.tqdm \n",
    "##else:\n",
    "    ##from tqdm import tqdm_notebook as tqdm\n",
    "    \n",
    "def plot_9_digits(MNIST_dataset):\n",
    "    # plot the first 9 training images in MNIST\n",
    "    fig, ax = plt.subplots(3, 3, figsize = (10, 10))\n",
    "    fig.suptitle('First 9 images of MNIST')\n",
    "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
    "    for x, y in [(i, j) for i in range(3) for j in range(3)]:\n",
    "        ax[x, y].axis('off')\n",
    "        ax[x, y].imshow(MNIST_dataset[x + y * 3][0].squeeze(), cmap = 'inferno')\n",
    "        ax[x, y].set_title(MNIST_dataset[x + y * 3][1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the training and test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_train_dataset = datasets.MNIST('data', train=True, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                           transforms.Resize([32, 32]),\n",
    "                           transforms.ToTensor()\n",
    "                           ]))\n",
    "\n",
    "MNIST_test_dataset = datasets.MNIST('data', train=False, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                           transforms.Resize([32, 32]),\n",
    "                           transforms.ToTensor()\n",
    "                           ]))\n",
    "\n",
    "\n",
    "print(\"N train samples: {}\".format(len(MNIST_train_dataset)))\n",
    "print(\"N test samples: {}\".format(len(MNIST_test_dataset)))\n",
    "\n",
    "plot_9_digits(MNIST_train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your network using `nn.sequential`. With `nn.sequential` you can simply list sequentially all the layers that form your neural network.\n",
    "\n",
    "hints:\n",
    "- the equivalent of numpy arrays are called tensors in pytorch\n",
    "- pytorch processes data in batches, data have ususally 4 dimensions: [number of samples in the batch] x [number of features] x [spatial dimension] x [spatial dimension 2]\n",
    "- usually the network is composed by a series of blocks each made of a sequence of: one linear layer (fully connected or convolutional layer) followed by a non-linearity (relu, tanh or sigmoid) followed by a pooling layer (average pooling or max pooling). For the MNIST dataset a set of 2-3 of such blocks should be enough.\n",
    "- last layer should be a linear layer that outputs a tensor of dimension [number of samples in the batch] x [number of classes] \n",
    "- `nn.Flatten()` might be a useful module. it transforms a tensor of shape $[N,F, D_1, D_2]$ in one of dimension $[N,F\\cdot D_1 \\cdot D_2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 10\n",
    "input_channels = 1\n",
    "input_spatial_dim = 32\n",
    "\n",
    "\n",
    "model = nn.Sequential(#nn.Linear(32,512, bias = False),\n",
    "                        #nn.ReLU(),\n",
    "                        nn.Flatten(),\n",
    "                        \n",
    "                      nn.Linear(1024, number_of_classes, bias=False),\n",
    "                        \n",
    "                    )\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model =model.to(device)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "logstep = int(1000 // batch_size)\n",
    "\n",
    "train_loader = datatorch.DataLoader(MNIST_train_dataset,batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "test_loader = datatorch.DataLoader(MNIST_test_dataset,batch_size=batch_size, shuffle=False,drop_last=True)\n",
    "\n",
    "lr = 0.01 # learning rate\n",
    "# optimizer: you can use torch.optim.SGD, torch.optim.Adam  or any other provided in pytorch lib\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loss_vec = []\n",
    "training_accuracy_vec = []\n",
    "model.train()\n",
    "for e in tqdm(range(0,epochs)):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr/10**e) ## optimiser with converging learningrate\n",
    "    print(e)\n",
    "    training_loss = 0.\n",
    "    training_accuracy = 0.\n",
    "    with tqdm(train_loader,leave=False) as tnr:\n",
    "        tnr.set_postfix(training_loss= np.nan,training_accuracy=np.nan)\n",
    "        for n,(x,y) in enumerate(tnr):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad() #  always call this function at the beginning of each step. it basically \"cleans\" the computational graph\n",
    "            \n",
    "            y_pred =  model(x)# compute the prediction using the model\n",
    "            \n",
    "            loss = criterion(y_pred, y) # compute the loss using the batch labels, the predictions and the criterion\n",
    "            \n",
    "            # tell pytorch to compute the gradients wrt the loss\n",
    "            loss.backward()\n",
    "            \n",
    "            # tell pytorch optimizer to make a step using the newly computed gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # update stats\n",
    "            training_loss += loss.item()\n",
    "            y_pred_idx = torch.max(y_pred.detach().cpu(),dim=1)[1]\n",
    "            training_accuracy += torch.mean((y_pred_idx == y.cpu()).float()).item()\n",
    "            if (n+1) % logstep == 0:\n",
    "                tnr.set_postfix(training_loss=training_loss/logstep,training_accuracy=training_accuracy/logstep) \n",
    "                training_loss_vec.append(training_loss/logstep)\n",
    "                training_accuracy_vec.append(training_accuracy/logstep)\n",
    "                training_loss, training_accuracy = 0.,0.\n",
    "                \n",
    "\n",
    "plt.plot(logstep*np.arange(1,1+len(training_loss_vec)),np.array(training_loss_vec))\n",
    "plt.ylabel(\"loss criterion\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.show()\n",
    "plt.plot(logstep*np.arange(1,1+len(training_accuracy_vec)),np.array(training_accuracy_vec))\n",
    "plt.ylabel(\"training accuracy\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.show()\n",
    "\n",
    "test_accuracy = 0.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for (x,y) in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "                \n",
    "        y_pred = model(x)\n",
    "\n",
    "        y_pred_idx = torch.max(y_pred.detach().cpu(),dim=1)[1]\n",
    "        test_accuracy += torch.mean((y_pred_idx == y.cpu()).float())\n",
    "\n",
    "    test_accuracy = test_accuracy/len(test_loader)\n",
    "        \n",
    "print(\"test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the `optimizer` will take care of performing the gradient descent for you, the parameter `lr` modifies the learning rate.\n",
    "- choose a loss to be used for a classification task (see lecture slides and use only [pytorch loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- change the architecture of the network model and the learning rate and observe how the learning curves and performance change.\n",
    "- which non-linearity did you pick? do you notice big performance variation among them? (relu, sigmoid, tanh, leakyRelu...)\n",
    "- How many hidden layers did your best model have? what was the feature dimension of the hidden layers?\n",
    "- what accuracy on the test dataset can you achieve if you use a single linear fully connected layer on the MNIST dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "#### 2.  I picked the ReLU as a non-linearity function. Yes, there are big different up to 10% accuracy between the non-linear functions\n",
    "#### 3.  2 hidden Layers with (32,512) , (16384,2)\n",
    "#### 4.  I get around 92.5% test accuracy with a single linear layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (3+2 pts)\n",
    "\n",
    "There is a competition [https://www.kaggle.com/c/dogs-vs-cats-mvml-2020/overview](https://www.kaggle.com/c/dogs-vs-cats-mvml-2020/overview). You should create the model, train it, and upload the predictions on kaggle to get the test score on the test set. The first 3 places on the scoreboard will get 2 extra points, between the 4th and 10th place you will get 1 extra point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch ## added\n",
    "import os\n",
    "import cv2\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms ### added\n",
    "import torch.utils.data as datatorch ### added\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split #added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'cats_vs_dogs/cats_vs_dogs'\n",
    "test_dir = 'test/test'\n",
    "train_files = os.listdir(train_dir)\n",
    "test_files = os.listdir(test_dir)\n",
    "\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, file_list, dir, mode='train', transform = None):\n",
    "        self.file_list = file_list\n",
    "        self.dir = dir\n",
    "        self.mode= mode\n",
    "        self.transform = transform\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.dir, self.file_list[idx]))\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            if 'dog' in self.file_list[idx]:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mode == 'train':\n",
    "            img = img.numpy()\n",
    "            return img.astype('float32'), label\n",
    "        else:\n",
    "            img = img.numpy()\n",
    "            return img.astype('float32'), int(self.file_list[idx][:-4])\n",
    "        \n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = CatDogDataset(train_files, train_dir, transform = data_transform)\n",
    "test_dataset = CatDogDataset(test_files, test_dir, mode=\"test\" ,transform = data_transform_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cat.0.jpg\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(train_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  0.6951242781454517 traing_acc:  0.49899193548387094\n",
      "training loss:  0.6931425832932995 traing_acc:  0.5080645161290323\n",
      "training loss:  0.6934984845499839 traing_acc:  0.4798387096774194\n",
      "training loss:  0.6932290600192162 traing_acc:  0.47681451612903225\n",
      "training loss:  0.6931477208291331 traing_acc:  0.5\n",
      "training loss:  0.6932996011549427 traing_acc:  0.4647177419354839\n",
      "training loss:  0.693170024502662 traing_acc:  0.4969758064516129\n",
      "training loss:  0.6931369516157335 traing_acc:  0.4899193548387097\n",
      "training loss:  0.6943091442508083 traing_acc:  0.5120967741935484\n",
      "training loss:  0.6944015103001748 traing_acc:  0.4899193548387097\n",
      "training loss:  0.6932998434189828 traing_acc:  0.4939516129032258\n",
      "training loss:  0.6931248730228793 traing_acc:  0.5141129032258065\n",
      "training loss:  0.6932845538662326 traing_acc:  0.4899193548387097\n",
      "training loss:  0.6931777538791779 traing_acc:  0.4889112903225806\n",
      "training loss:  0.6931769482551082 traing_acc:  0.48588709677419356\n",
      "training loss:  0.6931252171916347 traing_acc:  0.5050403225806451\n",
      "training loss:  0.6932416212174201 traing_acc:  0.4949596774193548\n",
      "training loss:  0.6931033653597678 traing_acc:  0.5080645161290323\n",
      "training loss:  0.69313403291087 traing_acc:  0.5231854838709677\n",
      "training loss:  0.6930856339393123 traing_acc:  0.5151209677419355\n",
      "training loss:  0.6930677352413055 traing_acc:  0.5120967741935484\n",
      "training loss:  0.693183091378981 traing_acc:  0.49899193548387094\n",
      "training loss:  0.693227348789092 traing_acc:  0.4949596774193548\n",
      "training loss:  0.6933334700522884 traing_acc:  0.4778225806451613\n",
      "training loss:  0.6931732354625579 traing_acc:  0.4959677419354839\n",
      "training loss:  0.6937626158037493 traing_acc:  0.5030241935483871\n",
      "training loss:  0.6931458115577698 traing_acc:  0.5040322580645161\n",
      "training loss:  0.693011624197806 traing_acc:  0.5090725806451613\n",
      "training loss:  0.6920621837339094 traing_acc:  0.48185483870967744\n",
      "training loss:  0.6906321817828763 traing_acc:  0.5342741935483871\n",
      "training loss:  0.6905099826474344 traing_acc:  0.53125\n",
      "training loss:  0.6881425572979835 traing_acc:  0.5352822580645161\n",
      "training loss:  0.6844959105214765 traing_acc:  0.5534274193548387\n",
      "training loss:  0.6847716223809027 traing_acc:  0.5554435483870968\n",
      "training loss:  0.6855233542380794 traing_acc:  0.5534274193548387\n",
      "training loss:  0.6877458480096632 traing_acc:  0.532258064516129\n",
      "training loss:  0.6884584061561092 traing_acc:  0.5554435483870968\n",
      "training loss:  0.6823929202172064 traing_acc:  0.5715725806451613\n",
      "training loss:  0.6847224639308068 traing_acc:  0.5685483870967742\n",
      "training loss:  0.6650724622511095 traing_acc:  0.5897177419354839\n",
      "training loss:  0.6888629544165826 traing_acc:  0.563508064516129\n",
      "training loss:  0.6701566480821178 traing_acc:  0.5655241935483871\n",
      "training loss:  0.6784670333708486 traing_acc:  0.5715725806451613\n",
      "training loss:  0.6675826234202231 traing_acc:  0.5625\n",
      "training loss:  0.654372134516316 traing_acc:  0.6038306451612904\n",
      "training loss:  0.6386951438842281 traing_acc:  0.6280241935483871\n",
      "training loss:  0.6521729980745623 traing_acc:  0.6300403225806451\n",
      "training loss:  0.6447018750252262 traing_acc:  0.626008064516129\n",
      "training loss:  0.6592563121549545 traing_acc:  0.6270161290322581\n",
      "training loss:  0.6402112110968559 traing_acc:  0.6421370967741935\n",
      "training loss:  0.6452314930577432 traing_acc:  0.6401209677419355\n",
      "training loss:  0.6543813520862211 traing_acc:  0.6199596774193549\n",
      "training loss:  0.6358778688215441 traing_acc:  0.6481854838709677\n",
      "training loss:  0.614501045596215 traing_acc:  0.6653225806451613\n",
      "training loss:  0.6696613354067649 traing_acc:  0.5897177419354839\n",
      "training loss:  0.6541715668093774 traing_acc:  0.6068548387096774\n",
      "training loss:  0.6251004588219428 traing_acc:  0.65625\n",
      "training loss:  0.6394059696505147 traing_acc:  0.655241935483871\n",
      "training loss:  0.6242054124032298 traing_acc:  0.6512096774193549\n",
      "training loss:  0.6328559671678851 traing_acc:  0.6481854838709677\n",
      "training loss:  0.6184534661231502 traing_acc:  0.6703629032258065\n",
      "training loss:  0.6310932828534034 traing_acc:  0.6461693548387096\n",
      "training loss:  0.6332973914761697 traing_acc:  0.6421370967741935\n",
      "training loss:  0.6074698029025909 traing_acc:  0.6693548387096774\n",
      "training loss:  0.6095850996432766 traing_acc:  0.6713709677419355\n",
      "training loss:  0.6100215421568963 traing_acc:  0.6643145161290323\n",
      "training loss:  0.6070534971452528 traing_acc:  0.6764112903225806\n",
      "training loss:  0.6236708914079974 traing_acc:  0.6703629032258065\n",
      "training loss:  0.6116287131463328 traing_acc:  0.6764112903225806\n",
      "training loss:  0.6243463620062797 traing_acc:  0.6542338709677419\n",
      "training loss:  0.6230041192423913 traing_acc:  0.6673387096774194\n",
      "training loss:  0.6136454305341167 traing_acc:  0.6633064516129032\n",
      "training loss:  0.6114818924857724 traing_acc:  0.6764112903225806\n",
      "training loss:  0.5961088653533689 traing_acc:  0.6925403225806451\n",
      "training loss:  0.5863851847187165 traing_acc:  0.6975806451612904\n",
      "training loss:  0.598065278222484 traing_acc:  0.7016129032258065\n",
      "training loss:  0.5854314959818318 traing_acc:  0.7016129032258065\n",
      "training loss:  0.6176363893093602 traing_acc:  0.6703629032258065\n",
      "training loss:  0.6135944551037203 traing_acc:  0.6754032258064516\n",
      "training loss:  0.6152528851262985 traing_acc:  0.6713709677419355\n",
      "training loss:  0.5965691285748635 traing_acc:  0.6824596774193549\n",
      "training loss:  0.5908691363949929 traing_acc:  0.6975806451612904\n",
      "training loss:  0.609863438913899 traing_acc:  0.6824596774193549\n",
      "training loss:  0.592850330375856 traing_acc:  0.6915322580645161\n",
      "training loss:  0.581797836288329 traing_acc:  0.7147177419354839\n",
      "training loss:  0.5920791020316463 traing_acc:  0.686491935483871\n",
      "training loss:  0.5928812190409629 traing_acc:  0.6905241935483871\n",
      "training loss:  0.5904009332579951 traing_acc:  0.7096774193548387\n",
      "training loss:  0.5965720530479185 traing_acc:  0.688508064516129\n",
      "training loss:  0.615595656056558 traing_acc:  0.6683467741935484\n",
      "training loss:  0.5898583377561262 traing_acc:  0.6915322580645161\n",
      "training loss:  0.599452922421117 traing_acc:  0.6804435483870968\n",
      "training loss:  0.5815340568942409 traing_acc:  0.7157258064516129\n",
      "training loss:  0.5726454344487959 traing_acc:  0.7207661290322581\n",
      "training loss:  0.5753747811240535 traing_acc:  0.7247983870967742\n",
      "training loss:  0.5805351811070596 traing_acc:  0.7116935483870968\n",
      "training loss:  0.5646514931032734 traing_acc:  0.7348790322580645\n",
      "training loss:  0.5724608975072061 traing_acc:  0.7217741935483871\n",
      "training loss:  0.5953394213030415 traing_acc:  0.6955645161290323\n",
      "training loss:  0.5844055020040081 traing_acc:  0.6985887096774194\n",
      "training loss:  0.5900602148425195 traing_acc:  0.6955645161290323\n",
      "training loss:  0.5731918244592605 traing_acc:  0.7237903225806451\n",
      "training loss:  0.5691960559737298 traing_acc:  0.7167338709677419\n",
      "training loss:  0.569347087414034 traing_acc:  0.7227822580645161\n",
      "training loss:  0.5785229571403996 traing_acc:  0.7127016129032258\n",
      "training loss:  0.5591100290898354 traing_acc:  0.7449596774193549\n",
      "training loss:  0.5633915268605755 traing_acc:  0.7338709677419355\n",
      "training loss:  0.5488920461746954 traing_acc:  0.7449596774193549\n",
      "training loss:  0.5747510925416024 traing_acc:  0.7207661290322581\n",
      "training loss:  0.5523220339129048 traing_acc:  0.7389112903225806\n",
      "training loss:  0.564844258369938 traing_acc:  0.7247983870967742\n",
      "training loss:  0.5742784594335864 traing_acc:  0.7096774193548387\n",
      "training loss:  0.5772518419450329 traing_acc:  0.7137096774193549\n",
      "training loss:  0.5448168987228025 traing_acc:  0.751008064516129\n",
      "training loss:  0.5729512649197732 traing_acc:  0.717741935483871\n",
      "training loss:  0.5566299682663333 traing_acc:  0.7399193548387096\n",
      "training loss:  0.5279763235199836 traing_acc:  0.780241935483871\n",
      "training loss:  0.5624169697684627 traing_acc:  0.7207661290322581\n",
      "training loss:  0.5652674830728962 traing_acc:  0.7247983870967742\n",
      "training loss:  0.555985995838719 traing_acc:  0.7429435483870968\n",
      "training loss:  0.534802298392019 traing_acc:  0.7641129032258065\n",
      "training loss:  0.5575904221304001 traing_acc:  0.7389112903225806\n",
      "training loss:  0.5536128513274654 traing_acc:  0.7429435483870968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  0.5389063060283661 traing_acc:  0.7610887096774194\n",
      "training loss:  0.5429203644875558 traing_acc:  0.7540322580645161\n",
      "training loss:  0.5503722823435261 traing_acc:  0.7409274193548387\n",
      "training loss:  0.541482973483301 traing_acc:  0.7560483870967742\n",
      "training loss:  0.545272474327395 traing_acc:  0.7540322580645161\n",
      "training loss:  0.5405171119397686 traing_acc:  0.7641129032258065\n",
      "training loss:  0.5351110168041722 traing_acc:  0.7620967741935484\n",
      "training loss:  0.5498432507438045 traing_acc:  0.7469758064516129\n",
      "training loss:  0.5328553318977356 traing_acc:  0.7600806451612904\n",
      "training loss:  0.5327577831283692 traing_acc:  0.7782258064516129\n",
      "training loss:  0.5566734786956541 traing_acc:  0.7429435483870968\n",
      "training loss:  0.5261819141526376 traing_acc:  0.7711693548387096\n",
      "training loss:  0.5419116068270898 traing_acc:  0.7590725806451613\n",
      "training loss:  0.5276100702824131 traing_acc:  0.7711693548387096\n",
      "training loss:  0.533801999784285 traing_acc:  0.7580645161290323\n",
      "training loss:  0.5342533155795066 traing_acc:  0.7641129032258065\n",
      "training loss:  0.5413195779246669 traing_acc:  0.7610887096774194\n",
      "training loss:  0.5463993482051357 traing_acc:  0.7520161290322581\n",
      "training loss:  0.5583566090753002 traing_acc:  0.7328629032258065\n",
      "training loss:  0.5142221768056193 traing_acc:  0.7933467741935484\n",
      "training loss:  0.515949837623104 traing_acc:  0.78125\n",
      "training loss:  0.542250653428416 traing_acc:  0.7580645161290323\n",
      "training loss:  0.5302001401301353 traing_acc:  0.7741935483870968\n",
      "training loss:  0.5282415286187203 traing_acc:  0.7701612903225806\n",
      "training loss:  0.5525947818833012 traing_acc:  0.7419354838709677\n",
      "training loss:  0.536612150169188 traing_acc:  0.7631048387096774\n",
      "training loss:  0.5217779249914231 traing_acc:  0.7762096774193549\n",
      "training loss:  0.5206031587816053 traing_acc:  0.782258064516129\n",
      "training loss:  0.5341669417196705 traing_acc:  0.7671370967741935\n",
      "training loss:  0.539439223466381 traing_acc:  0.7540322580645161\n",
      "training loss:  0.5426042541380851 traing_acc:  0.7479838709677419\n",
      "training loss:  0.5287554312136865 traing_acc:  0.7741935483870968\n",
      "training loss:  0.5204834563116874 traing_acc:  0.7731854838709677\n",
      "training loss:  0.5260795835525759 traing_acc:  0.7711693548387096\n",
      "training loss:  0.533805747185984 traing_acc:  0.7580645161290323\n",
      "training loss:  0.528766829159952 traing_acc:  0.7741935483870968\n",
      "training loss:  0.5067459594818854 traing_acc:  0.7923387096774194\n",
      "training loss:  0.5276427192072715 traing_acc:  0.7701612903225806\n",
      "training loss:  0.5074897927622641 traing_acc:  0.8014112903225806\n",
      "training loss:  0.5446473494652779 traing_acc:  0.75\n",
      "training loss:  0.5200325317921177 traing_acc:  0.78125\n",
      "training loss:  0.5138871823587725 traing_acc:  0.7953629032258065\n",
      "training loss:  0.5127986054266652 traing_acc:  0.7933467741935484\n",
      "training loss:  0.5351893969120518 traing_acc:  0.7671370967741935\n",
      "training loss:  0.5143002242811264 traing_acc:  0.7983870967741935\n",
      "training loss:  0.5247060743070417 traing_acc:  0.7782258064516129\n",
      "training loss:  0.5225001688926451 traing_acc:  0.7772177419354839\n",
      "training loss:  0.504821329347549 traing_acc:  0.7983870967741935\n",
      "training loss:  0.5179280052261968 traing_acc:  0.782258064516129\n",
      "training loss:  0.5041170889331449 traing_acc:  0.7893145161290323\n",
      "training loss:  0.5185266463987289 traing_acc:  0.7792338709677419\n",
      "training loss:  0.5069325710496595 traing_acc:  0.7913306451612904\n",
      "training loss:  0.5327661546968645 traing_acc:  0.7671370967741935\n",
      "training loss:  0.5150049694122807 traing_acc:  0.7933467741935484\n",
      "training loss:  0.527509335548647 traing_acc:  0.7731854838709677\n",
      "training loss:  0.510284750692306 traing_acc:  0.7842741935483871\n",
      "training loss:  0.5114723847758386 traing_acc:  0.7963709677419355\n",
      "training loss:  0.5122011746129682 traing_acc:  0.7842741935483871\n",
      "training loss:  0.5076348829653955 traing_acc:  0.7933467741935484\n",
      "training loss:  0.49485651716109247 traing_acc:  0.811491935483871\n",
      "training loss:  0.49402855577007415 traing_acc:  0.8094758064516129\n",
      "training loss:  0.5072259979863321 traing_acc:  0.7943548387096774\n",
      "training loss:  0.5349182967216738 traing_acc:  0.7610887096774194\n",
      "training loss:  0.4925331117645387 traing_acc:  0.8165322580645161\n",
      "training loss:  0.5044814348220825 traing_acc:  0.7983870967741935\n",
      "training loss:  0.5293896611659757 traing_acc:  0.7741935483870968\n",
      "training loss:  0.5097211493599799 traing_acc:  0.7893145161290323\n",
      "training loss:  0.5135330346322828 traing_acc:  0.78125\n",
      "training loss:  0.5103716984871896 traing_acc:  0.7893145161290323\n",
      "training loss:  0.4939897281508292 traing_acc:  0.8094758064516129\n",
      "training loss:  0.5051664315885113 traing_acc:  0.7943548387096774\n",
      "training loss:  0.5130314788510723 traing_acc:  0.7923387096774194\n",
      "training loss:  0.5016942091526524 traing_acc:  0.7953629032258065\n",
      "training loss:  0.490954521202272 traing_acc:  0.8145161290322581\n",
      "training loss:  0.4993850156184166 traing_acc:  0.7973790322580645\n",
      "training loss:  0.49639165786004835 traing_acc:  0.8084677419354839\n",
      "training loss:  0.4810114041451485 traing_acc:  0.8296370967741935\n",
      "training loss:  0.48957345754869525 traing_acc:  0.8155241935483871\n",
      "training loss:  0.5003110708728913 traing_acc:  0.7903225806451613\n",
      "training loss:  0.5180579558495553 traing_acc:  0.7862903225806451\n",
      "training loss:  0.4989571321395136 traing_acc:  0.7993951612903226\n",
      "training loss:  0.5110098037027544 traing_acc:  0.782258064516129\n",
      "training loss:  0.4882985968743601 traing_acc:  0.8104838709677419\n",
      "training loss:  0.49472509661028463 traing_acc:  0.8125\n",
      "training loss:  0.5152595764206301 traing_acc:  0.780241935483871\n",
      "training loss:  0.500985728156182 traing_acc:  0.8024193548387096\n",
      "training loss:  0.5242244976182138 traing_acc:  0.7752016129032258\n",
      "training loss:  0.510199228602071 traing_acc:  0.7943548387096774\n",
      "training loss:  0.5013066376409223 traing_acc:  0.8024193548387096\n",
      "training loss:  0.5119735637018757 traing_acc:  0.7832661290322581\n",
      "training loss:  0.4954098597649605 traing_acc:  0.8104838709677419\n",
      "training loss:  0.5070758510020471 traing_acc:  0.7913306451612904\n",
      "training loss:  0.499720734934653 traing_acc:  0.8014112903225806\n",
      "training loss:  0.5008629666220757 traing_acc:  0.7963709677419355\n",
      "training loss:  0.499800875302284 traing_acc:  0.7973790322580645\n",
      "training loss:  0.4904429518407391 traing_acc:  0.8125\n",
      "training loss:  0.5195729357580985 traing_acc:  0.782258064516129\n",
      "training loss:  0.48747469052191705 traing_acc:  0.8145161290322581\n",
      "training loss:  0.519635284139264 traing_acc:  0.7762096774193549\n",
      "training loss:  0.49009863022835026 traing_acc:  0.8145161290322581\n",
      "training loss:  0.4914225378344136 traing_acc:  0.8155241935483871\n",
      "training loss:  0.5065783800617341 traing_acc:  0.7983870967741935\n",
      "training loss:  0.48756236318619023 traing_acc:  0.8125\n",
      "training loss:  0.5078952600879054 traing_acc:  0.7903225806451613\n",
      "training loss:  0.4913641983462918 traing_acc:  0.8044354838709677\n",
      "training loss:  0.5019382536411285 traing_acc:  0.8044354838709677\n",
      "training loss:  0.5045733788321095 traing_acc:  0.7993951612903226\n",
      "training loss:  0.4888771205179153 traing_acc:  0.811491935483871\n",
      "training loss:  0.5004727167467917 traing_acc:  0.7983870967741935\n",
      "training loss:  0.4837815232815281 traing_acc:  0.8235887096774194\n",
      "training loss:  0.5018656340337568 traing_acc:  0.7973790322580645\n",
      "training loss:  0.4921232711884283 traing_acc:  0.8145161290322581\n",
      "training loss:  0.505596705982762 traing_acc:  0.7973790322580645\n",
      "training loss:  0.4792563751820595 traing_acc:  0.8316532258064516\n",
      "training loss:  0.48829490042501883 traing_acc:  0.8235887096774194\n",
      "training loss:  0.49172443439883573 traing_acc:  0.8094758064516129\n",
      "training loss:  0.48563728986247895 traing_acc:  0.8185483870967742\n",
      "training loss:  0.4867289585451926 traing_acc:  0.811491935483871\n",
      "training loss:  0.4954038079707853 traing_acc:  0.8074596774193549\n",
      "training loss:  0.5213546916361778 traing_acc:  0.7691532258064516\n",
      "training loss:  0.48578325683070767 traing_acc:  0.8175403225806451\n",
      "training loss:  0.4860111686491197 traing_acc:  0.8195564516129032\n",
      "training loss:  0.5007807948896962 traing_acc:  0.7993951612903226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  0.48043490129132427 traing_acc:  0.8235887096774194\n",
      "training loss:  0.482116824196231 traing_acc:  0.8215725806451613\n",
      "training loss:  0.5079695024797993 traing_acc:  0.7943548387096774\n",
      "training loss:  0.5018919812094781 traing_acc:  0.7983870967741935\n",
      "training loss:  0.5066139323096122 traing_acc:  0.7953629032258065\n",
      "training loss:  0.4959609873833195 traing_acc:  0.8034274193548387\n",
      "training loss:  0.4874815633220057 traing_acc:  0.8125\n",
      "training loss:  0.48335202182492903 traing_acc:  0.8175403225806451\n",
      "training loss:  0.4769161199369738 traing_acc:  0.8276209677419355\n",
      "training loss:  0.49267606773684103 traing_acc:  0.8125\n",
      "training loss:  0.5017983913421631 traing_acc:  0.8024193548387096\n",
      "training loss:  0.4818927559160417 traing_acc:  0.8215725806451613\n",
      "training loss:  0.4812731204494353 traing_acc:  0.8276209677419355\n",
      "training loss:  0.498814030039695 traing_acc:  0.8014112903225806\n",
      "training loss:  0.48649474882310434 traing_acc:  0.8175403225806451\n",
      "training loss:  0.4801004432862805 traing_acc:  0.8256048387096774\n",
      "training loss:  0.48185424650869063 traing_acc:  0.8245967741935484\n",
      "training loss:  0.4939006249750814 traing_acc:  0.811491935483871\n",
      "training loss:  0.49178888144031646 traing_acc:  0.8145161290322581\n",
      "training loss:  0.4903716694924139 traing_acc:  0.8185483870967742\n",
      "training loss:  0.4720203597699442 traing_acc:  0.8377016129032258\n",
      "training loss:  0.4794184440566647 traing_acc:  0.8235887096774194\n",
      "training loss:  0.49616253760553175 traing_acc:  0.8094758064516129\n",
      "training loss:  0.4830928194907404 traing_acc:  0.8165322580645161\n",
      "training loss:  0.509002975879177 traing_acc:  0.7913306451612904\n",
      "training loss:  0.4842871312172182 traing_acc:  0.8225806451612904\n",
      "training loss:  0.47097012592900184 traing_acc:  0.8326612903225806\n",
      "training loss:  0.49166318870359854 traing_acc:  0.8104838709677419\n",
      "training loss:  0.47800897302166107 traing_acc:  0.8185483870967742\n",
      "training loss:  0.5080530672304092 traing_acc:  0.7852822580645161\n",
      "training loss:  0.4744611324802522 traing_acc:  0.8316532258064516\n",
      "training loss:  0.46246739452885044 traing_acc:  0.8326612903225806\n",
      "training loss:  0.4911141751273986 traing_acc:  0.8125\n",
      "training loss:  0.47578160801241476 traing_acc:  0.8256048387096774\n",
      "training loss:  0.4846786558628082 traing_acc:  0.8175403225806451\n",
      "training loss:  0.4767773324443448 traing_acc:  0.8276209677419355\n",
      "training loss:  0.4993667967857853 traing_acc:  0.8024193548387096\n",
      "training loss:  0.4960649446133644 traing_acc:  0.8084677419354839\n",
      "training loss:  0.48602285788905236 traing_acc:  0.8175403225806451\n",
      "training loss:  0.47777613901322885 traing_acc:  0.8256048387096774\n",
      "training loss:  0.46116401495472076 traing_acc:  0.8467741935483871\n",
      "training loss:  0.48141893359922594 traing_acc:  0.8235887096774194\n",
      "training loss:  0.48131425438388703 traing_acc:  0.8235887096774194\n",
      "training loss:  0.47390830516815186 traing_acc:  0.8316532258064516\n",
      "training loss:  0.4861526450803203 traing_acc:  0.813508064516129\n",
      "training loss:  0.4767132593739417 traing_acc:  0.8286290322580645\n",
      "training loss:  0.4758195963598067 traing_acc:  0.8326612903225806\n",
      "training loss:  0.4788692141732862 traing_acc:  0.8286290322580645\n",
      "training loss:  0.4748573755064318 traing_acc:  0.8276209677419355\n",
      "training loss:  0.46533437890391194 traing_acc:  0.842741935483871\n",
      "training loss:  0.4753686458833756 traing_acc:  0.8286290322580645\n",
      "training loss:  0.4790636089540297 traing_acc:  0.8346774193548387\n",
      "training loss:  0.46855645506612714 traing_acc:  0.8387096774193549\n",
      "training loss:  0.46608639244110356 traing_acc:  0.8387096774193549\n",
      "training loss:  0.48659827536152256 traing_acc:  0.8175403225806451\n",
      "training loss:  0.48716130948835806 traing_acc:  0.8125\n",
      "training loss:  0.487885344413019 traing_acc:  0.8155241935483871\n",
      "training loss:  0.4587477676330074 traing_acc:  0.8518145161290323\n",
      "training loss:  0.4684810157745115 traing_acc:  0.8387096774193549\n",
      "training loss:  0.47295594407666114 traing_acc:  0.8266129032258065\n",
      "training loss:  0.48715450975202745 traing_acc:  0.8175403225806451\n",
      "training loss:  0.49858332833936136 traing_acc:  0.8034274193548387\n",
      "training loss:  0.48199390788232127 traing_acc:  0.8215725806451613\n",
      "training loss:  0.4674022976429232 traing_acc:  0.8366935483870968\n",
      "training loss:  0.48157136863277805 traing_acc:  0.8256048387096774\n",
      "training loss:  0.47808356054367557 traing_acc:  0.8266129032258065\n",
      "training loss:  0.46624340645728574 traing_acc:  0.8397177419354839\n",
      "training loss:  0.47701916098594666 traing_acc:  0.8306451612903226\n",
      "training loss:  0.471033945198982 traing_acc:  0.8336693548387096\n",
      "training loss:  0.45683449314486596 traing_acc:  0.8518145161290323\n",
      "training loss:  0.4702843629544781 traing_acc:  0.8387096774193549\n",
      "training loss:  0.46398801188315114 traing_acc:  0.8377016129032258\n",
      "training loss:  0.4780231435452738 traing_acc:  0.8245967741935484\n",
      "training loss:  0.46672515138503046 traing_acc:  0.8417338709677419\n",
      "training loss:  0.45878415819137325 traing_acc:  0.844758064516129\n",
      "training loss:  0.46790548582230845 traing_acc:  0.8336693548387096\n",
      "training loss:  0.46880422292217133 traing_acc:  0.8377016129032258\n",
      "training loss:  0.4930559713994303 traing_acc:  0.8074596774193549\n",
      "training loss:  0.4784543264296747 traing_acc:  0.8256048387096774\n",
      "training loss:  0.4848828459939649 traing_acc:  0.8165322580645161\n",
      "training loss:  0.4720839108190229 traing_acc:  0.8326612903225806\n",
      "training loss:  0.47056685628429534 traing_acc:  0.8377016129032258\n",
      "training loss:  0.4790320079172811 traing_acc:  0.8195564516129032\n",
      "training loss:  0.46030447656108486 traing_acc:  0.8528225806451613\n",
      "training loss:  0.4635132503124975 traing_acc:  0.8397177419354839\n",
      "training loss:  0.4806139440305771 traing_acc:  0.8245967741935484\n",
      "training loss:  0.47382932132290256 traing_acc:  0.8326612903225806\n",
      "training loss:  0.4860901803739609 traing_acc:  0.8175403225806451\n",
      "training loss:  0.45925251610817447 traing_acc:  0.842741935483871\n",
      "training loss:  0.47128146502279467 traing_acc:  0.8336693548387096\n",
      "training loss:  0.46400306782414835 traing_acc:  0.8346774193548387\n",
      "training loss:  0.47064462496388343 traing_acc:  0.8377016129032258\n",
      "training loss:  0.4825502701344029 traing_acc:  0.8235887096774194\n",
      "training loss:  0.4712762861482559 traing_acc:  0.8326612903225806\n",
      "training loss:  0.4650488640031507 traing_acc:  0.8467741935483871\n",
      "training loss:  0.4991095575594133 traing_acc:  0.8074596774193549\n",
      "training loss:  0.4647112642565081 traing_acc:  0.8457661290322581\n",
      "training loss:  0.45388579753137404 traing_acc:  0.8518145161290323\n",
      "training loss:  0.46147046166081584 traing_acc:  0.8407258064516129\n",
      "training loss:  0.46112422212477655 traing_acc:  0.8518145161290323\n",
      "training loss:  0.45527655559201397 traing_acc:  0.8497983870967742\n",
      "training loss:  0.45590031819958843 traing_acc:  0.8457661290322581\n",
      "training loss:  0.4672096496628177 traing_acc:  0.8387096774193549\n",
      "training loss:  0.4739929812569772 traing_acc:  0.8306451612903226\n",
      "training loss:  0.4677027213958002 traing_acc:  0.8387096774193549\n",
      "training loss:  0.4660442711845521 traing_acc:  0.8336693548387096\n",
      "training loss:  0.4652072854580418 traing_acc:  0.8387096774193549\n",
      "training loss:  0.4819292551086795 traing_acc:  0.8205645161290323\n",
      "training loss:  0.47341968263349227 traing_acc:  0.8326612903225806\n",
      "training loss:  0.4825217406595907 traing_acc:  0.8266129032258065\n",
      "training loss:  0.46020586163766924 traing_acc:  0.84375\n",
      "training loss:  0.48534136914437814 traing_acc:  0.8175403225806451\n",
      "training loss:  0.4655916065939011 traing_acc:  0.8407258064516129\n",
      "training loss:  0.48465941029210247 traing_acc:  0.8195564516129032\n",
      "training loss:  0.5628238156918557 traing_acc:  0.7288306451612904\n",
      "training loss:  0.5258879334695877 traing_acc:  0.7741935483870968\n",
      "training loss:  0.4776063580666819 traing_acc:  0.8235887096774194\n",
      "training loss:  0.4729355987041227 traing_acc:  0.8276209677419355\n",
      "training loss:  0.46612340884823955 traing_acc:  0.8407258064516129\n",
      "training loss:  0.45847672608590895 traing_acc:  0.8518145161290323\n",
      "training loss:  0.4665274495078671 traing_acc:  0.8417338709677419\n",
      "training loss:  0.44128662540066627 traing_acc:  0.8679435483870968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  0.4727123062456808 traing_acc:  0.8306451612903226\n",
      "training loss:  0.44604981618542827 traing_acc:  0.8588709677419355\n",
      "training loss:  0.4778162202527446 traing_acc:  0.8256048387096774\n",
      "training loss:  0.476064823327526 traing_acc:  0.8326612903225806\n",
      "training loss:  0.46858640832285725 traing_acc:  0.8346774193548387\n",
      "training loss:  0.4402265683297188 traing_acc:  0.875\n",
      "training loss:  0.4475951752355022 traing_acc:  0.8629032258064516\n",
      "training loss:  0.4626891093869363 traing_acc:  0.8366935483870968\n",
      "training loss:  0.4723202307378092 traing_acc:  0.8276209677419355\n",
      "training loss:  0.46621417710858004 traing_acc:  0.8417338709677419\n",
      "training loss:  0.4590824640566303 traing_acc:  0.844758064516129\n",
      "training loss:  0.45643157055301053 traing_acc:  0.8548387096774194\n",
      "training loss:  0.4551222526258038 traing_acc:  0.8497983870967742\n",
      "training loss:  0.453626750938354 traing_acc:  0.8538306451612904\n",
      "training loss:  0.46639180760229787 traing_acc:  0.8366935483870968\n",
      "training loss:  0.4498562284054295 traing_acc:  0.8618951612903226\n",
      "training loss:  0.47464586746308113 traing_acc:  0.8377016129032258\n",
      "training loss:  0.46883970499038696 traing_acc:  0.8336693548387096\n",
      "training loss:  0.4447139463117046 traing_acc:  0.8608870967741935\n",
      "training loss:  0.49165755414193674 traing_acc:  0.8074596774193549\n",
      "training loss:  0.47587127647092264 traing_acc:  0.8316532258064516\n",
      "training loss:  0.46644635065909357 traing_acc:  0.8397177419354839\n",
      "training loss:  0.4561451212052376 traing_acc:  0.8497983870967742\n",
      "training loss:  0.4579366368632163 traing_acc:  0.8497983870967742\n",
      "training loss:  0.4573504905546865 traing_acc:  0.8548387096774194\n",
      "training loss:  0.46074354744726614 traing_acc:  0.8377016129032258\n",
      "training loss:  0.45539794814202095 traing_acc:  0.8538306451612904\n",
      "training loss:  0.4580517622732347 traing_acc:  0.8518145161290323\n",
      "training loss:  0.4588401327210088 traing_acc:  0.8467741935483871\n",
      "training loss:  0.4582078581856143 traing_acc:  0.8508064516129032\n",
      "training loss:  0.45827743026518053 traing_acc:  0.8457661290322581\n",
      "training loss:  0.45235382453087836 traing_acc:  0.8487903225806451\n",
      "training loss:  0.4695754128117715 traing_acc:  0.8366935483870968\n",
      "training loss:  0.4671460880387214 traing_acc:  0.8387096774193549\n",
      "training loss:  0.4570280861470007 traing_acc:  0.844758064516129\n",
      "training loss:  0.4551702218670999 traing_acc:  0.8548387096774194\n",
      "training loss:  0.44330667776446187 traing_acc:  0.8639112903225806\n",
      "training loss:  0.4486316298284838 traing_acc:  0.8679435483870968\n",
      "training loss:  0.4667167355937342 traing_acc:  0.8417338709677419\n",
      "training loss:  0.46594498811229584 traing_acc:  0.842741935483871\n",
      "training loss:  0.4911455223637243 traing_acc:  0.8084677419354839\n",
      "training loss:  0.45172825167256014 traing_acc:  0.8528225806451613\n",
      "training loss:  0.4575303360339134 traing_acc:  0.8558467741935484\n",
      "training loss:  0.4650569087074649 traing_acc:  0.8356854838709677\n",
      "training loss:  0.44244508589467696 traing_acc:  0.8639112903225806\n",
      "training loss:  0.47110680514766323 traing_acc:  0.8407258064516129\n",
      "training loss:  0.478401183120666 traing_acc:  0.8286290322580645\n",
      "training loss:  0.4557106898676965 traing_acc:  0.8508064516129032\n",
      "training loss:  0.4445686513377774 traing_acc:  0.8679435483870968\n",
      "training loss:  0.44980971370973893 traing_acc:  0.8548387096774194\n",
      "training loss:  0.45624237964230197 traing_acc:  0.8497983870967742\n",
      "training loss:  0.4682635116961695 traing_acc:  0.8316532258064516\n",
      "training loss:  0.44608165948621686 traing_acc:  0.8578629032258065\n",
      "training loss:  0.45623086633220794 traing_acc:  0.8477822580645161\n",
      "training loss:  0.45839845941912744 traing_acc:  0.8497983870967742\n",
      "training loss:  0.44132490023489923 traing_acc:  0.8699596774193549\n",
      "training loss:  0.4522306130778405 traing_acc:  0.8518145161290323\n",
      "training loss:  0.45256941453103094 traing_acc:  0.8568548387096774\n",
      "training loss:  0.45291544256671784 traing_acc:  0.8518145161290323\n",
      "training loss:  0.4587900446307275 traing_acc:  0.8487903225806451\n",
      "training loss:  0.47929619108476945 traing_acc:  0.8235887096774194\n",
      "training loss:  0.4869916246783349 traing_acc:  0.8155241935483871\n",
      "training loss:  0.45253252790820214 traing_acc:  0.8598790322580645\n",
      "training loss:  0.42942224971709714 traing_acc:  0.8800403225806451\n",
      "training loss:  0.4616145232031422 traing_acc:  0.842741935483871\n",
      "training loss:  0.44182535333018147 traing_acc:  0.873991935483871\n",
      "training loss:  0.4530348287474725 traing_acc:  0.8518145161290323\n",
      "training loss:  0.47058166611579155 traing_acc:  0.8336693548387096\n",
      "training loss:  0.46215151394567183 traing_acc:  0.844758064516129\n",
      "training loss:  0.44238215684890747 traing_acc:  0.8699596774193549\n",
      "training loss:  0.4678290505563059 traing_acc:  0.8336693548387096\n",
      "training loss:  0.4557775701245954 traing_acc:  0.8518145161290323\n",
      "training loss:  0.4572092467738736 traing_acc:  0.84375\n",
      "training loss:  0.43247870764424723 traing_acc:  0.875\n",
      "training loss:  0.46077289408253086 traing_acc:  0.8477822580645161\n",
      "training loss:  0.4435111668802077 traing_acc:  0.8629032258064516\n",
      "training loss:  0.4528836444500954 traing_acc:  0.8508064516129032\n",
      "training loss:  0.4496463421852358 traing_acc:  0.8578629032258065\n",
      "training loss:  0.44504239193854794 traing_acc:  0.8649193548387096\n",
      "training loss:  0.438846270884237 traing_acc:  0.8639112903225806\n",
      "training loss:  0.4467123285416634 traing_acc:  0.8538306451612904\n",
      "training loss:  0.46482142613780114 traing_acc:  0.842741935483871\n",
      "training loss:  0.46473042234297723 traing_acc:  0.8387096774193549\n",
      "training loss:  0.4429136024367425 traing_acc:  0.8709677419354839\n",
      "training loss:  0.45380446410948233 traing_acc:  0.8508064516129032\n",
      "training loss:  0.4393496378775566 traing_acc:  0.8649193548387096\n",
      "training loss:  0.4464434366072378 traing_acc:  0.8649193548387096\n",
      "training loss:  0.4520014524459839 traing_acc:  0.8528225806451613\n",
      "training loss:  0.4543501273278267 traing_acc:  0.8538306451612904\n",
      "training loss:  0.4365169973142685 traing_acc:  0.8770161290322581\n",
      "training loss:  0.45825046204751535 traing_acc:  0.8467741935483871\n",
      "training loss:  0.45201444433581445 traing_acc:  0.8558467741935484\n",
      "training loss:  0.4449067884875882 traing_acc:  0.8608870967741935\n",
      "training loss:  0.450024212560346 traing_acc:  0.8558467741935484\n",
      "training loss:  0.45518644394413116 traing_acc:  0.8508064516129032\n",
      "training loss:  0.46253436419271654 traing_acc:  0.844758064516129\n",
      "training loss:  0.4376919384925596 traing_acc:  0.8699596774193549\n",
      "training loss:  0.450358675372216 traing_acc:  0.8538306451612904\n",
      "training loss:  0.44913917299239864 traing_acc:  0.8639112903225806\n",
      "training loss:  0.44573014493911495 traing_acc:  0.8548387096774194\n",
      "training loss:  0.43856125108657346 traing_acc:  0.8669354838709677\n",
      "training loss:  0.46004944462930003 traing_acc:  0.8387096774193549\n",
      "training loss:  0.4692722837771139 traing_acc:  0.8356854838709677\n",
      "training loss:  0.4600478785653268 traing_acc:  0.8417338709677419\n",
      "training loss:  0.45546602241454587 traing_acc:  0.8558467741935484\n",
      "training loss:  0.4502343641173455 traing_acc:  0.8528225806451613\n",
      "training loss:  0.43773934918065227 traing_acc:  0.8719758064516129\n",
      "training loss:  0.44978100734372295 traing_acc:  0.8467741935483871\n",
      "training loss:  0.46376619896581095 traing_acc:  0.8377016129032258\n",
      "training loss:  0.4494308175579194 traing_acc:  0.8618951612903226\n",
      "training loss:  0.4611413651897061 traing_acc:  0.8397177419354839\n",
      "training loss:  0.44898396538149926 traing_acc:  0.8578629032258065\n",
      "training loss:  0.43303427004045053 traing_acc:  0.8780241935483871\n",
      "training loss:  0.4423968772734365 traing_acc:  0.8618951612903226\n",
      "training loss:  0.4593852239270364 traing_acc:  0.8467741935483871\n",
      "training loss:  0.4350140142825342 traing_acc:  0.8790322580645161\n",
      "training loss:  0.441655364728743 traing_acc:  0.8669354838709677\n",
      "training loss:  0.4516991742195622 traing_acc:  0.8487903225806451\n",
      "training loss:  0.4483705239911233 traing_acc:  0.8588709677419355\n",
      "training loss:  0.45207894136828763 traing_acc:  0.842741935483871\n",
      "training loss:  0.4561537936810524 traing_acc:  0.8528225806451613\n",
      "training loss:  0.4363411982213297 traing_acc:  0.876008064516129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  0.4412248759500442 traing_acc:  0.8679435483870968\n",
      "training loss:  0.4437821449772004 traing_acc:  0.8629032258064516\n",
      "training loss:  0.44839056461088117 traing_acc:  0.8618951612903226\n",
      "training loss:  0.4353615016706528 traing_acc:  0.876008064516129\n",
      "training loss:  0.44903827963336823 traing_acc:  0.8608870967741935\n",
      "training loss:  0.43982835546616583 traing_acc:  0.8699596774193549\n",
      "training loss:  0.4565765223195476 traing_acc:  0.8477822580645161\n",
      "training loss:  0.45096547757425615 traing_acc:  0.8558467741935484\n",
      "training loss:  0.41926452421372934 traing_acc:  0.8911290322580645\n",
      "training loss:  0.44152815591904426 traing_acc:  0.8608870967741935\n",
      "training loss:  0.4557263014778014 traing_acc:  0.8508064516129032\n",
      "training loss:  0.43022040686299723 traing_acc:  0.876008064516129\n",
      "training loss:  0.44633880257606506 traing_acc:  0.8548387096774194\n",
      "training loss:  0.4362100516596148 traing_acc:  0.875\n",
      "training loss:  0.42999332278005536 traing_acc:  0.8790322580645161\n",
      "training loss:  0.46260014945460903 traing_acc:  0.8497983870967742\n",
      "training loss:  0.43560334655546373 traing_acc:  0.876008064516129\n",
      "training loss:  0.43253395730449307 traing_acc:  0.873991935483871\n",
      "training loss:  0.41795008509389814 traing_acc:  0.8951612903225806\n",
      "training loss:  0.4342161570825884 traing_acc:  0.8729838709677419\n",
      "training loss:  0.44659895954593537 traing_acc:  0.8689516129032258\n",
      "training loss:  0.4380199188186276 traing_acc:  0.875\n",
      "training loss:  0.44054273059291227 traing_acc:  0.8679435483870968\n",
      "training loss:  0.43766479915188206 traing_acc:  0.876008064516129\n",
      "training loss:  0.4462315113313736 traing_acc:  0.8639112903225806\n",
      "training loss:  0.4537107675306259 traing_acc:  0.8558467741935484\n",
      "training loss:  0.46968662931073096 traing_acc:  0.8326612903225806\n",
      "training loss:  0.451157194952811 traing_acc:  0.8518145161290323\n",
      "training loss:  0.42777128469559456 traing_acc:  0.8810483870967742\n",
      "training loss:  0.42835657154360124 traing_acc:  0.8780241935483871\n",
      "training loss:  0.448392923801176 traing_acc:  0.8568548387096774\n",
      "training loss:  0.4318394584040488 traing_acc:  0.8770161290322581\n",
      "training loss:  0.4334330443413027 traing_acc:  0.876008064516129\n",
      "training loss:  0.4360338401409887 traing_acc:  0.8679435483870968\n",
      "training loss:  0.4415129250095737 traing_acc:  0.8608870967741935\n",
      "training loss:  0.43108489436487996 traing_acc:  0.8790322580645161\n",
      "training loss:  0.43756001034090597 traing_acc:  0.8770161290322581\n",
      "training loss:  0.46754052562098347 traing_acc:  0.8387096774193549\n",
      "training loss:  0.44002841845635443 traing_acc:  0.8618951612903226\n",
      "training loss:  0.43814726125809456 traing_acc:  0.8699596774193549\n",
      "training loss:  0.4451568809247786 traing_acc:  0.8618951612903226\n",
      "training loss:  0.4404046227855067 traing_acc:  0.8659274193548387\n",
      "training loss:  0.4361432108186906 traing_acc:  0.8709677419354839\n",
      "training loss:  0.43897963723828715 traing_acc:  0.873991935483871\n",
      "training loss:  0.43797412995369206 traing_acc:  0.8649193548387096\n",
      "training loss:  0.43358310672544664 traing_acc:  0.876008064516129\n",
      "training loss:  0.435522384220554 traing_acc:  0.8709677419354839\n",
      "training loss:  0.4257136881351471 traing_acc:  0.8850806451612904\n",
      "training loss:  0.4387140879707952 traing_acc:  0.8719758064516129\n",
      "training loss:  0.4399993467715479 traing_acc:  0.8639112903225806\n"
     ]
    }
   ],
   "source": [
    "##### first download the dataset and unzipped the image folders ## done\n",
    "\n",
    "# set parameters (learning rate, batch size, number of epochs...)\n",
    "learning_rate = 0.002\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "logstep = int(1000 // batch_size)\n",
    "num_workers = 0\n",
    "\n",
    "# create dataloader for training dataset\n",
    "train_loader = datatorch.DataLoader(dataset=train_dataset, \n",
    "                         shuffle=True, \n",
    "                         batch_size=batch_size)\n",
    "\n",
    "\n",
    "# create network model\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(9,9)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            nn.Flatten(),\n",
    "            torch.nn.Linear(6400, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 2),\n",
    "            torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cuda:0\")\n",
    "model =model.to(device)\n",
    "# create optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[500,1000,1500], gamma=0.5)\n",
    "\n",
    "training_loss_vec = []\n",
    "training_accuracy_vec = []\n",
    "\n",
    "# loop over epochs\n",
    "model.train()\n",
    "for e in range(epochs):\n",
    "    training_loss = 0.\n",
    "    training_accuracy = 0.\n",
    "    for n, (x,y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        #print(x.shape)\n",
    "        # call optimizer.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        # compute predictions using model\n",
    "        y_pred =  model(x)\n",
    "        # compute loss\n",
    "        loss = criterion(y_pred, y)\n",
    "        # run backward method\n",
    "        loss.backward()\n",
    "        # run optimizer step\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # logging (optional)\n",
    "        training_loss += loss.item()\n",
    "        y_pred_idx = torch.max(y_pred.detach().cpu(),dim=1)[1]\n",
    "        training_accuracy += torch.mean((y_pred_idx == y.cpu()).float()).item()\n",
    "        if (n+1) % logstep == 0: \n",
    "            training_loss_vec.append(training_loss/logstep)\n",
    "            training_accuracy_vec.append(training_accuracy/logstep)\n",
    "            print('training loss: ', training_loss/logstep,'traing_acc: ',training_accuracy/logstep)\n",
    "            training_loss, training_accuracy = 0.,0.\n",
    "   \n",
    "\n",
    "# create dataloader for test dataset\n",
    "# get predictions, save the file and submit it to kaggle (see the kaggle page for info on the submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(logstep*np.arange(1,1+len(training_loss_vec)),np.array(training_loss_vec))\n",
    "plt.ylabel(\"loss criterion\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.show()\n",
    "plt.plot(logstep*np.arange(1,1+len(training_accuracy_vec)),np.array(training_accuracy_vec))\n",
    "plt.ylabel(\"training accuracy\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.show()\n",
    "print(max(training_accuracy_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/jaeboklee/pytorch-cat-vs-dog\n",
    "testloader = datatorch.DataLoader(test_dataset, batch_size = 1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "fn_list = []\n",
    "pred_list = []\n",
    "i = 0\n",
    "for x, fn in testloader:\n",
    "    with torch.no_grad():\n",
    "        x = x.to(device)\n",
    "        output = model(x)\n",
    "        \n",
    "        \n",
    "        pred = torch.argmax(output, dim=1)\n",
    "       \n",
    "        fn_list.append(fn.item())\n",
    "        pred_list += [p.item() for p in pred]\n",
    "        \n",
    "\n",
    "submission = pd.DataFrame({\"id\":fn_list, \"label\":pred_list})\n",
    "submission.to_csv('submission7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fn_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 88.8%\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            nn.Flatten(),\n",
    "            torch.nn.Linear(9216, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 2),\n",
    "            torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#needs to be tested\n",
    "model = torch.nn.Sequential(\n",
    "       nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(9,9)),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2)),\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(9,9)),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2)),\n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(9,9)),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2)),\n",
    "        nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(3,3)),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2)),\n",
    "        nn.Linear(64,32,bias = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.8),\n",
    "        nn.Linear(32,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_accuracy = 0.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for (x,y) in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "                \n",
    "        y_pred = model(x)\n",
    "\n",
    "        y_pred_idx = torch.max(y_pred.detach().cpu(),dim=1)[1]\n",
    "        test_accuracy += torch.mean((y_pred_idx == y.cpu()).float())\n",
    "\n",
    "    test_accuracy = test_accuracy/len(test_loader)\n",
    "        \n",
    "print(\"test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss += loss.item()\n",
    "        y_pred_idx = torch.max(y_pred.detach().cpu(),dim=1)[1]\n",
    "        training_accuracy += torch.mean((y_pred_idx == y.cpu()).float()).item()\n",
    "        if (n+1) % logstep == 0:\n",
    "            tnr.set_postfix(training_loss=training_loss/logstep,training_accuracy=training_accuracy/logstep) \n",
    "            training_loss_vec.append(training_loss/logstep)\n",
    "            training_accuracy_vec.append(training_accuracy/logstep)\n",
    "            training_loss, training_accuracy = 0.,0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "model = torch.nn.Sequential(\n",
    "       nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(9,9)),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2)),\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(9,9)),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2)),\n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(9,9)),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2)),\n",
    "        nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(3,3)),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2)),\n",
    "        nn.Linear(64,32,bias = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.8),\n",
    "        nn.Linear(32,2)\n",
    ")\n",
    "\n",
    "\n",
    "convnet = input_data(shape=[None, IMAGE_SIZE, IMAGE_SIZE, 1], name='input')\n",
    "#Conv Layer 1\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "#Conv Layer 2\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "#Conv Layer 3\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "#Conv Layer 4\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "#Conv Layer 5\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "#Conv Layer 6\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "#Fully Connected Layer with SoftMax as Activation Function\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(5,5), stride=2, padding=1)\n",
    "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(5,5), stride=2, padding=1)\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=1)\n",
    "        \n",
    "        nn.BatchNorm2d(64)\n",
    "        nn.Dropout(0.5)\n",
    "        \n",
    "        nn.Linear(in_features=64*2*2, out_features=200)\n",
    "        nn.Linear(in_features=200, out_features=20)\n",
    "        nn.Linear(in_features=20, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Flatten(),\n",
    "                                nn.Linear(196608, 256),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(256, 2),\n",
    "                                 nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(num_in_features, hidden_layers, num_out_features):       \n",
    "    classifier = nn.Sequential()    \n",
    "    if hidden_layers == None:        \n",
    "        classifier.add_module('fc0', nn.Linear(num_in_features, 102))    \n",
    "    else:        \n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])        \n",
    "        classifier.add_module('fc0', nn.Linear(num_in_features, hidden_layers[0]))        \n",
    "        classifier.add_module('relu0', nn.ReLU())        \n",
    "        classifier.add_module('drop0', nn.Dropout(.6))        \n",
    "        classifier.add_module('relu1', nn.ReLU())        \n",
    "        classifier.add_module('drop1', nn.Dropout(.5))        \n",
    "    for i, (h1, h2) in enumerate(layer_sizes):            \n",
    "        classifier.add_module('fc'+str(i+1), nn.Linear(h1, h2))            \n",
    "        classifier.add_module('relu'+str(i+1), nn.ReLU())            \n",
    "        classifier.add_module('drop'+str(i+1), nn.Dropout(.5)) \n",
    "        \n",
    "    classifier.add_module('output', nn.Linear(hidden_layers[-1], num_out_features))            \n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(123,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.6),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(.5),\n",
    "    \n",
    "    nn.Linear(128, 64),       \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(.5),\n",
    "    \n",
    "    nn.Linear(64, 32),       \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(.5),\n",
    "    \n",
    "    nn.Linear(32, 16),       \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(.5),\n",
    "    \n",
    "    nn.Linear(16,2)\n",
    "    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.1",
    "jupytext_version": "1.2.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
