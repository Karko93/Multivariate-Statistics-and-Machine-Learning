{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Statistik und Machine Learning: Assignment 6\n",
    "In this exercise you will learn how to use neural networs in simulated and real datasets.\n",
    "\n",
    "Please note it is important to answer questions when they are given, as we will reduce points in case no specific answer is given.\n",
    "\n",
    "For this we will use the [Pytorch](https://pytorch.org) library. You can install pytorch using`conda` environment or `pip` (see pytorch website).\n",
    "you will also need `conda install -c pytorch torchvision`\n",
    "\n",
    "__Team work is not allowed__. Everybody implements his/her own code. Discussing issues with others is fine, sharing code and/or answers with others is __not__. If you use any code fragments found on the Internet, make sure you reference them properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1, 1pt\n",
    "\n",
    "In this first exercise we are going to get an idea on how simple neural networks\n",
    "behave for simple classification tasks. We’ll make use of two different javascript\n",
    "based neural network to train and modify an existing model. Let’s start with a very\n",
    "simple one, a simple neural network with only fully connected layers and without\n",
    "convolutions. Open a web browser on the page http://playground.tensorflow.org/ and start playing with the interface. For each dataset set the noise level to 30. Click play on the top-left to start training. To assess the quality of the network look at the values train and test loss at the top right. Tip: Sometimes it’s easier\n",
    "to see the result if you discretise the graph.\n",
    "\n",
    "\n",
    "1. For the spiral dataset try to design the best architecture you can to solve the problem.\n",
    "\n",
    "To get the point in this task you need to add a screenshot to the submission zip file with the best architecture and answer the following:\n",
    "\n",
    "- Now try to find an architecture that is as small as possible (low number of layers, low number of neurons), With a smaller architecture, can you keep a similar performance? You can support your answer with the test-loss numbers from the test set. \n",
    "- In the spiral dataset, do you observe any advantages of having a deep network (more layers) than a wider network (more neurons per layer)? Which one performs better in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "#### Yes, the smallest architecture with the best performance I could found was 3 hidden layers and with (8 neurons,8 neurons, 1 neuron) --> the criteria for the best performance was the robustness of this noisy data (noise = 30) in aspect to the test loss. the test loss was more or less constant around ~0.02 (which was also the smallest) with different regenerated data\n",
    "#### Deeper Networks seem to converge faster and tend to less overfit but on my opinion wider networks work better in this case because the test loss seems to be lower in general in this situation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The following part is optional, but fun!__ Open this page https://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html and try to tweak all the parameters you can to obtain the best network (the highest validation accuracy).\n",
    "Scroll down the page and peek inside the network and have a look at different\n",
    "activation and weight as the network gets trained (click pause to make it freeze).\n",
    "Check how the prediction works on the test set in the last part of the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 Backpropagation, 3 pts\n",
    "\n",
    "As you saw in the lecture neural networks are just a stack of simple functions, interlayered with non-linearity functions to model complex problems. Everything must be differentiable to use convex optimizers. For any of such optmizers, we need to compute gradients from the output of the network with respect to the input. Which can be easily computed using the chain rule. \n",
    "\n",
    "Let our neural network be defined by the function $f(x) = h_1(h_2(h_3(x)))$.\n",
    "\n",
    "Using the chain rule we can compute \n",
    "\n",
    "\n",
    "$$ \\dfrac{\\partial f}{\\partial x} = \\dfrac{\\partial h_1}{\\partial h_2} \\dfrac{\\partial h_2}{\\partial x} $$\n",
    "\n",
    "$$ \\dfrac{\\partial f}{\\partial x} = \\dfrac{\\partial h_1}{\\partial h_2} \\dfrac{\\partial h_2}{\\partial h_3}  \\dfrac{\\partial h_3}{\\partial x}$$\n",
    "\n",
    "\n",
    "let $h_1$ and $h_3$ be linear layer of the form $h_1(x) = w_1*x$ and $h_3(x) = 2*w_3*x+b_3+1$. For simplicity we will use an identity instead of a nonlinearity like ReLU or tanh.\n",
    "\n",
    "\n",
    "#### Ex.3.1 Write down the partial derivatives of $h_1$ and $h_3$.\n",
    "\n",
    "This should be done with respect to the input and each of the parameters ($x, w_1, w_3, b_3$). Here we ask you for the formula not the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\dfrac{\\partial h_1}{\\partial x} = w_1 $$\n",
    "$$ \\dfrac{\\partial h_1}{\\partial w_1} = x $$\n",
    "$$ \\dfrac{\\partial h_3}{\\partial x} = 2 \\cdot w_3 $$\n",
    "$$ \\dfrac{\\partial h_3}{\\partial w_3} = 2 \\cdot x $$\n",
    "$$ \\dfrac{\\partial h_3}{\\partial b_3} = 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such linear layers are already implemented in most common frameworks. And have automated gradient computation. In Pytorch this is called [Autograd](https://pytorch.org/docs/stable/autograd.html). In pytorch a linear function is defined in the `torch.nn.Linear` class.\n",
    "\n",
    "Which means all the derivatives $\\dfrac{\\partial h_1}{\\partial x}$ and $\\dfrac{\\partial h_3}{\\partial x}$ are computed automatically with autograd.\n",
    "\n",
    "The following code is an example implementation of a Linear function ([see source](https://pytorch.org/docs/stable/notes/extending.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Inherit from Function\n",
    "class LinearFunction(torch.autograd.Function):\n",
    "\n",
    "    # Note that both forward and backward are @staticmethods\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias=None):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        output = input.mm(weight.t())\n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "        return output\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # This is a pattern that is very convenient - at the top of backward\n",
    "        # unpack saved_tensors and initialize all gradients w.r.t. inputs to\n",
    "        # None. Thanks to the fact that additional trailing Nones are\n",
    "        # ignored, the return statement is simple even when the function has\n",
    "        # optional inputs.\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "        # These needs_input_grad checks are optional and there only to\n",
    "        # improve efficiency. If you want to make your code simpler, you can\n",
    "        # skip them. Returning gradients for inputs that don't require it is\n",
    "        # not an error.\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            # df/dx = w\n",
    "            grad_input = grad_output.mm(weight)\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            # df/dw = x\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            # df/fb = 1\n",
    "            grad_bias = grad_output.sum(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return grad_input, grad_weight, grad_bias\n",
    "        \n",
    "        \n",
    "        \n",
    "linear = LinearFunction.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "batch = 2\n",
    "in_dim = 4\n",
    "out_dim = 3\n",
    "\n",
    "input = (torch.randn(batch,in_dim,dtype=torch.double,requires_grad=True), # input data\n",
    "         torch.randn(out_dim,in_dim,dtype=torch.double,requires_grad=True),\n",
    "         torch.randn(out_dim,dtype=torch.double,requires_grad=True), # bias\n",
    "        )\n",
    "test = torch.autograd.gradcheck(linear, input, eps=1e-6, atol=1e-4)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex.2.2 Implement $h_2(x)$ in pytorch.\n",
    "\n",
    "\n",
    "Stacking linear functions with non-linearities creates powerful networks to tackle complex tasks. Some times however more complicaded functions are most fitted to certain settings (e.g. physical constrains, optimization constrains, etc.). Which is why we may need to implement a more complex function in a single layer.\n",
    "\n",
    "Let $h_2$ has the form:\n",
    "\n",
    "$$h_2(x) =  w_{21}*x + w_{22}*x^2 +exp(w_{23}*x)+b_2$$\n",
    "\n",
    "\n",
    "Use the MyFunction class skeleton below. You need to:\n",
    "- write the forward pass (i.e. feed the inputs through the function using the function's parameters)\n",
    "- write your own implementation of the backward pass (i.e. compute $\\dfrac{\\partial h_2}{\\partial x}$ and return the product with the previous gradient. In our example the `grad_output` would be equivalent to $\\dfrac{\\partial h_1}{\\partial h_2}$ and the function should return the product of `grad_output` and the gradients with respect to each of the inputs \n",
    "$(\\dfrac{\\partial h_1}{\\partial h_2}\\dfrac{\\partial h_2}{\\partial x},\n",
    "  \\dfrac{\\partial h_1}{\\partial h_2}\\dfrac{\\partial h_2}{\\partial w_{21}},\n",
    "  \\dfrac{\\partial h_1}{\\partial h_2}\\dfrac{\\partial h_2}{\\partial w_{22}},...)$. \n",
    "\n",
    "Note that you need to return gradients with respect to each of the inputs involved in $h_2$ in the same order the were recieved in the forward pass ($x, w_{21},w_{22},w_{23},b_{21}$).\n",
    "\n",
    "For simplicity, asume that the input is in $\\mathbb{R}^1$ and the function only outputs a single scalar. It must however be able to recieve batches of samples with the shape (batch, 1).\n",
    "\n",
    "\n",
    "Hints:\n",
    "\n",
    "- First write down the formulas of each of the partial derivatives, and then implement them. This should facilitate the writing of the code.\n",
    "- `tensor_x.t()` denotes transpose of tensor_x\n",
    "- for a matrix multiplication between x and y use `x.mm(y)`.\n",
    "- for basic operations you can use:  `tensor_a.sum(tensor_b)` ,  `tensor_a.mul(tensor_b)`,`tensor_a.pow(2)`, `torch.exp(x)` ,  etc. ([see more](https://pytorch.org/docs/stable/tensors.html))\n",
    "- it is important that the function returns pytorch tensors types.\n",
    "- in case you need to create new tensors, make sure they are of type `double`, this is necessarily to make the gradcheck function work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFunction(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, w21, w22=None, w23=None, b2=None):\n",
    "        ctx.save_for_backward(input, w21,w22,w23,b2)\n",
    "        \n",
    "        output = input.mm(w21)\n",
    "        if w22 is not None:\n",
    "            output += w22*input.pow(2)##\n",
    "        if w23 is not None:\n",
    "            output += torch.exp(w23*input)##\n",
    "        if b2 is not None:\n",
    "            output += b2##\n",
    "                 \n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # This is a pattern that is very convenient - at the top of backward\n",
    "        # unpack saved_tensors and initialize all gradients w.r.t. inputs to\n",
    "        # None. Thanks to the fact that additional trailing Nones are\n",
    "        # ignored, the return statement is simple even when the function has\n",
    "        # optional inputs.\n",
    "        input, w21, w22, w23, b2 = ctx.saved_tensors\n",
    "\n",
    "        \n",
    "        grad_input = grad_w21 = grad_w22 = grad_w23 = grad_b2 = None\n",
    "        print(grad_output.shape, input.shape)\n",
    "        grad_input = grad_output.mm(w21)\n",
    "        grad_w21 = grad_output.t().mm(input)\n",
    "        \n",
    "        #print(w22.shape)\n",
    "        if w22 is not None:\n",
    "            grad_input += grad_output.mul(2*input.mm(w22))\n",
    "        if w23 is not None:\n",
    "            grad_input += grad_output.mul(torch.exp(input.mm(w23))*w23)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if w22 is not None and ctx.needs_input_grad[2]:\n",
    "            grad_w22 = grad_output.t().mm(input.pow(2))\n",
    "            \n",
    "        if w23 is not None and ctx.needs_input_grad[3]:\n",
    "            grad_w23 = grad_output.t().mm(input.mul(torch.exp(input.mul(w23))))\n",
    "        if b2 is not None and ctx.needs_input_grad[4]:\n",
    "            grad_b2 = grad_output.sum(0)\n",
    "        \n",
    "        #print(grad_input.shape,grad_w21.shape, grad_w22.shape, grad_w23.shape, grad_b2.shape )\n",
    "        \n",
    "        return grad_input, grad_w21, grad_w22, grad_w23, grad_b2\n",
    "myfunction = MyFunction.apply   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code below you can test your implementation `gradcheck`performs a numerical computation of the gradient to verify that the analytical solution we wrote is correct.\n",
    "\n",
    "You omit some parameters to test the gradients one by one. For example: (input, w21) will compute and check only the gradients where w21 is involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1]) torch.Size([3, 1])\n",
      "torch.Size([3, 1]) torch.Size([3, 1])\n",
      "torch.Size([3, 1]) torch.Size([3, 1])\n",
      "torch.Size([3, 1]) torch.Size([3, 1])\n",
      "torch.Size([3, 1]) torch.Size([3, 1])\n",
      "torch.Size([3, 1]) torch.Size([3, 1])\n",
      "torch.Size([3, 1]) torch.Size([3, 1])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "batch = 3 #2\n",
    "d_in = 1\n",
    "d_out = 1\n",
    "input_test = (torch.randn(batch,d_in,dtype=torch.double,requires_grad=True), # input\n",
    "         torch.randn(d_out,d_in,dtype=torch.double,requires_grad=True), # w21\n",
    "         torch.randn(d_out,d_in,dtype=torch.double,requires_grad=False), # w22\n",
    "         torch.randn(d_out,d_in,dtype=torch.double,requires_grad=True), # w23\n",
    "         torch.randn(d_out,dtype=torch.double,requires_grad=True) # b21\n",
    "             )\n",
    "\n",
    "res = torch.autograd.gradcheck(myfunction, input_test, raise_exception=False)\n",
    "print(res) # res should be True if the gradients are correct.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of implentation of a pytorch module using the function we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H2(nn.Module):\n",
    "    def __init__(self, input_features, output_features, is_example=False):\n",
    "        # input_features define the dimension of the input\n",
    "        # output_features defines the dimensions of the output\n",
    "        \n",
    "        super(H2, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.output_features = output_features\n",
    "        \n",
    "        \n",
    "        self.w21 = nn.Parameter(torch.Tensor(output_features, input_features))\n",
    "        self.w21.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "        if is_example:\n",
    "            self.w22 = nn.Parameter(torch.Tensor(output_features, input_features))\n",
    "            self.w23 = nn.Parameter(torch.Tensor(output_features, input_features))\n",
    "            self.b2 = nn.Parameter(torch.Tensor(output_features))\n",
    "        \n",
    "            self.w22.data.uniform_(-0.1, 0.1)\n",
    "            self.w23.data.uniform_(-0.1, 0.1)\n",
    "            self.b2.data.uniform_(-0.1, 0.1)\n",
    "        else:\n",
    "            self.w22 = None\n",
    "            self.w23 = None\n",
    "            self.b2 = None\n",
    "            \n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        output = myfunction(input, self.w21,self.w22,self.w23, self.b2)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = H2(input_features=1,output_features=1, is_example=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1]) torch.Size([3, 1])\n",
      "tensor(3.1018, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,1)\n",
    "x_out = h2(x)\n",
    "\n",
    "dummy_loss = x_out.sum()\n",
    "dummy_loss.backward()\n",
    "print(dummy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3, 3pts\n",
    "\n",
    "In this exercise you have to train a new Convolutional Neural Network from scratch for the classification of images. The aim is to achieve a high score (98%-99% accuracy on the test set) on the MNIST dataset http://yann.lecun.com/exdb/mnist/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.utils.data as datatorch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import sys\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "##if 'ipykernel' in sys.modules: <--- this statement causes an error\n",
    "    ##import tqdm as tqdm_lib\n",
    "    ##tqdm = tqdm_lib.notebook.tqdm \n",
    "##else:\n",
    "    ##from tqdm import tqdm_notebook as tqdm\n",
    "    \n",
    "def plot_9_digits(MNIST_dataset):\n",
    "    # plot the first 9 training images in MNIST\n",
    "    fig, ax = plt.subplots(3, 3, figsize = (10, 10))\n",
    "    fig.suptitle('First 9 images of MNIST')\n",
    "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
    "    for x, y in [(i, j) for i in range(3) for j in range(3)]:\n",
    "        ax[x, y].axis('off')\n",
    "        ax[x, y].imshow(MNIST_dataset[x + y * 3][0].squeeze(), cmap = 'inferno')\n",
    "        ax[x, y].set_title(MNIST_dataset[x + y * 3][1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the training and test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train samples: 60000\n",
      "N test samples: 10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MNIST_train_dataset = datasets.MNIST('data', train=True, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                           transforms.Resize([32, 32]),\n",
    "                           transforms.ToTensor()\n",
    "                           ]))\n",
    "\n",
    "MNIST_test_dataset = datasets.MNIST('data', train=False, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                           transforms.Resize([32, 32]),\n",
    "                           transforms.ToTensor()\n",
    "                           ]))\n",
    "\n",
    "\n",
    "print(\"N train samples: {}\".format(len(MNIST_train_dataset)))\n",
    "print(\"N test samples: {}\".format(len(MNIST_test_dataset)))\n",
    "\n",
    "plot_9_digits(MNIST_train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your network using `nn.sequential`. With `nn.sequential` you can simply list sequentially all the layers that form your neural network.\n",
    "\n",
    "hints:\n",
    "- the equivalent of numpy arrays are called tensors in pytorch\n",
    "- pytorch processes data in batches, data have ususally 4 dimensions: [number of samples in the batch] x [number of features] x [spatial dimension] x [spatial dimension 2]\n",
    "- usually the network is composed by a series of blocks each made of a sequence of: one linear layer (fully connected or convolutional layer) followed by a non-linearity (relu, tanh or sigmoid) followed by a pooling layer (average pooling or max pooling). For the MNIST dataset a set of 2-3 of such blocks should be enough.\n",
    "- last layer should be a linear layer that outputs a tensor of dimension [number of samples in the batch] x [number of classes] \n",
    "- `nn.Flatten()` might be a useful module. it transforms a tensor of shape $[N,F, D_1, D_2]$ in one of dimension $[N,F\\cdot D_1 \\cdot D_2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421aa535cdf54a09ad04c12073b8c4ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=468), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=468), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.92578125\n"
     ]
    }
   ],
   "source": [
    "number_of_classes = 10\n",
    "input_channels = 1\n",
    "input_spatial_dim = 32\n",
    "\n",
    "\n",
    "model = nn.Sequential(#nn.Linear(32,512, bias = False),\n",
    "                        #nn.ReLU(),\n",
    "                        nn.Flatten(),\n",
    "                        \n",
    "                      nn.Linear(1024, number_of_classes, bias=False),\n",
    "                        \n",
    "                    )\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model =model.to(device)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "logstep = int(1000 // batch_size)\n",
    "\n",
    "train_loader = datatorch.DataLoader(MNIST_train_dataset,batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "test_loader = datatorch.DataLoader(MNIST_test_dataset,batch_size=batch_size, shuffle=False,drop_last=True)\n",
    "\n",
    "lr = 0.01 # learning rate\n",
    "# optimizer: you can use torch.optim.SGD, torch.optim.Adam  or any other provided in pytorch lib\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loss_vec = []\n",
    "training_accuracy_vec = []\n",
    "model.train()\n",
    "for e in tqdm(range(0,epochs)):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr/10**e) ## optimiser with converging learningrate\n",
    "    print(e)\n",
    "    training_loss = 0.\n",
    "    training_accuracy = 0.\n",
    "    with tqdm(train_loader,leave=False) as tnr:\n",
    "        tnr.set_postfix(training_loss= np.nan,training_accuracy=np.nan)\n",
    "        for n,(x,y) in enumerate(tnr):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad() #  always call this function at the beginning of each step. it basically \"cleans\" the computational graph\n",
    "            \n",
    "            y_pred =  model(x)# compute the prediction using the model\n",
    "            \n",
    "            loss = criterion(y_pred, y) # compute the loss using the batch labels, the predictions and the criterion\n",
    "            \n",
    "            # tell pytorch to compute the gradients wrt the loss\n",
    "            loss.backward()\n",
    "            \n",
    "            # tell pytorch optimizer to make a step using the newly computed gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # update stats\n",
    "            training_loss += loss.item()\n",
    "            y_pred_idx = torch.max(y_pred.detach().cpu(),dim=1)[1]\n",
    "            training_accuracy += torch.mean((y_pred_idx == y.cpu()).float()).item()\n",
    "            if (n+1) % logstep == 0:\n",
    "                tnr.set_postfix(training_loss=training_loss/logstep,training_accuracy=training_accuracy/logstep) \n",
    "                training_loss_vec.append(training_loss/logstep)\n",
    "                training_accuracy_vec.append(training_accuracy/logstep)\n",
    "                training_loss, training_accuracy = 0.,0.\n",
    "                \n",
    "\n",
    "plt.plot(logstep*np.arange(1,1+len(training_loss_vec)),np.array(training_loss_vec))\n",
    "plt.ylabel(\"loss criterion\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.show()\n",
    "plt.plot(logstep*np.arange(1,1+len(training_accuracy_vec)),np.array(training_accuracy_vec))\n",
    "plt.ylabel(\"training accuracy\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.show()\n",
    "\n",
    "test_accuracy = 0.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for (x,y) in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "                \n",
    "        y_pred = model(x)\n",
    "\n",
    "        y_pred_idx = torch.max(y_pred.detach().cpu(),dim=1)[1]\n",
    "        test_accuracy += torch.mean((y_pred_idx == y.cpu()).float())\n",
    "\n",
    "    test_accuracy = test_accuracy/len(test_loader)\n",
    "        \n",
    "print(\"test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the `optimizer` will take care of performing the gradient descent for you, the parameter `lr` modifies the learning rate.\n",
    "- choose a loss to be used for a classification task (see lecture slides and use only [pytorch loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- change the architecture of the network model and the learning rate and observe how the learning curves and performance change.\n",
    "- which non-linearity did you pick? do you notice big performance variation among them? (relu, sigmoid, tanh, leakyRelu...)\n",
    "- How many hidden layers did your best model have? what was the feature dimension of the hidden layers?\n",
    "- what accuracy on the test dataset can you achieve if you use a single linear fully connected layer on the MNIST dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "#### 2.  I picked the ReLU as a non-linearity function. Yes, there are big different up to 10% accuracy between the non-linear functions\n",
    "#### 3.  2 hidden Layers with (32,512) , (16384,2)\n",
    "#### 4.  I get around 92.5% test accuracy with a single linear layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (3+2 pts)\n",
    "\n",
    "There is a competition [https://www.kaggle.com/c/dogs-vs-cats-mvml-2020/overview](https://www.kaggle.com/c/dogs-vs-cats-mvml-2020/overview). You should create the model, train it, and upload the predictions on kaggle to get the test score on the test set. The first 3 places on the scoreboard will get 2 extra points, between the 4th and 10th place you will get 1 extra point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch ## added\n",
    "import os\n",
    "import cv2\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms ### added\n",
    "import torch.utils.data as datatorch ### added\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split #added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'cats_vs_dogs/cats_vs_dogs'\n",
    "test_dir = 'test/test'\n",
    "train_files = os.listdir(train_dir)\n",
    "test_files = os.listdir(test_dir)\n",
    "\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, file_list, dir, mode='train', transform = None):\n",
    "        self.file_list = file_list\n",
    "        self.dir = dir\n",
    "        self.mode= mode\n",
    "        self.transform = transform\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.dir, self.file_list[idx]))\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            if 'dog' in self.file_list[idx]:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mode == 'train':\n",
    "            img = img.numpy()\n",
    "            return img.astype('float32'), label\n",
    "        else:\n",
    "            img = img.numpy()\n",
    "            return img.astype('float32'), int(self.file_list[idx][:-4])\n",
    "        \n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = CatDogDataset(train_files, train_dir, transform = data_transform)\n",
    "test_dataset = CatDogDataset(test_files, test_dir, mode=\"test\" ,transform = data_transform_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cat.0.jpg\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(train_files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://wtfleming.github.io/2020/04/12/pytorch-cats-vs-dogs-part-3/\n",
    "model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  0.6939327239990234 traing_acc:  0.5041666666666667\n",
      "training loss:  0.694281788667043 traing_acc:  0.5010416666666667\n",
      "training loss:  0.6930465936660767 traing_acc:  0.5145833333333333\n",
      "training loss:  0.6930931568145752 traing_acc:  0.528125\n",
      "training loss:  0.6932179609934489 traing_acc:  0.5041666666666667\n",
      "training loss:  0.6923287590344747 traing_acc:  0.5364583333333334\n",
      "training loss:  0.6928732713063558 traing_acc:  0.5114583333333333\n",
      "training loss:  0.6923799355824788 traing_acc:  0.5208333333333334\n",
      "training loss:  0.694220503171285 traing_acc:  0.5083333333333333\n",
      "training loss:  0.6929142236709595 traing_acc:  0.48854166666666665\n",
      "training loss:  0.6912366509437561 traing_acc:  0.5385416666666667\n",
      "training loss:  0.6891286810239156 traing_acc:  0.5416666666666666\n",
      "training loss:  0.6842142025629679 traing_acc:  0.5375\n",
      "training loss:  0.6820948362350464 traing_acc:  0.5604166666666667\n",
      "training loss:  0.6742350816726684 traing_acc:  0.609375\n",
      "training loss:  0.6705012917518616 traing_acc:  0.5822916666666667\n",
      "training loss:  0.6699981888135275 traing_acc:  0.603125\n",
      "training loss:  0.6764398972193401 traing_acc:  0.5635416666666667\n",
      "training loss:  0.6755605379740397 traing_acc:  0.5729166666666666\n",
      "training loss:  0.6751344005266825 traing_acc:  0.5854166666666667\n",
      "training loss:  0.653931486606598 traing_acc:  0.6270833333333333\n",
      "training loss:  0.6549835920333862 traing_acc:  0.6114583333333333\n",
      "training loss:  0.6135260065396627 traing_acc:  0.6822916666666666\n",
      "training loss:  0.6083648681640625 traing_acc:  0.66875\n",
      "training loss:  0.6191902836163838 traing_acc:  0.6604166666666667\n",
      "training loss:  0.6278643250465393 traing_acc:  0.6541666666666667\n",
      "training loss:  0.6305086056391398 traing_acc:  0.665625\n",
      "training loss:  0.6264016350110372 traing_acc:  0.6604166666666667\n",
      "training loss:  0.6158390124638875 traing_acc:  0.6614583333333334\n",
      "training loss:  0.5932199120521545 traing_acc:  0.7020833333333333\n",
      "training loss:  0.5974629004796346 traing_acc:  0.69375\n",
      "training loss:  0.6150583982467651 traing_acc:  0.6739583333333333\n",
      "training loss:  0.612200935681661 traing_acc:  0.659375\n",
      "training loss:  0.5847475687662761 traing_acc:  0.7114583333333333\n",
      "training loss:  0.5710559089978536 traing_acc:  0.7145833333333333\n",
      "training loss:  0.5867319266001384 traing_acc:  0.6979166666666666\n",
      "training loss:  0.5836321473121643 traing_acc:  0.7104166666666667\n",
      "training loss:  0.5591607252756755 traing_acc:  0.7489583333333333\n",
      "training loss:  0.5553021868069966 traing_acc:  0.740625\n",
      "training loss:  0.5475516974925995 traing_acc:  0.75\n",
      "training loss:  0.5672915895779927 traing_acc:  0.7229166666666667\n",
      "training loss:  0.5635559419790904 traing_acc:  0.725\n",
      "training loss:  0.5527848303318024 traing_acc:  0.7354166666666667\n",
      "training loss:  0.5351903975009918 traing_acc:  0.7541666666666667\n",
      "training loss:  0.5683381497859955 traing_acc:  0.7260416666666667\n",
      "training loss:  0.5582973917325338 traing_acc:  0.7333333333333333\n",
      "training loss:  0.5518431425094604 traing_acc:  0.740625\n",
      "training loss:  0.5574013948440552 traing_acc:  0.7416666666666667\n",
      "training loss:  0.5551850159962972 traing_acc:  0.7364583333333333\n",
      "training loss:  0.5560695171356201 traing_acc:  0.734375\n",
      "training loss:  0.5356879293918609 traing_acc:  0.7614583333333333\n",
      "training loss:  0.528378959496816 traing_acc:  0.76875\n",
      "training loss:  0.5449151237805684 traing_acc:  0.7552083333333334\n",
      "training loss:  0.5245201408863067 traing_acc:  0.7739583333333333\n",
      "training loss:  0.5680342316627502 traing_acc:  0.7333333333333333\n",
      "training loss:  0.535180660088857 traing_acc:  0.7635416666666667\n",
      "training loss:  0.5435695648193359 traing_acc:  0.75625\n",
      "training loss:  0.5336643973986308 traing_acc:  0.7645833333333333\n",
      "training loss:  0.5188176572322846 traing_acc:  0.7770833333333333\n",
      "training loss:  0.5386448760827383 traing_acc:  0.75625\n",
      "training loss:  0.5255310793717702 traing_acc:  0.7645833333333333\n",
      "training loss:  0.5133711238702138 traing_acc:  0.7739583333333333\n",
      "training loss:  0.5331269641717274 traing_acc:  0.7614583333333333\n",
      "training loss:  0.5058562954266866 traing_acc:  0.796875\n",
      "training loss:  0.5123647332191468 traing_acc:  0.7854166666666667\n",
      "training loss:  0.497124449412028 traing_acc:  0.8114583333333333\n",
      "training loss:  0.5231097400188446 traing_acc:  0.7729166666666667\n",
      "training loss:  0.5119972447554271 traing_acc:  0.7885416666666667\n",
      "training loss:  0.5158578038215638 traing_acc:  0.7802083333333333\n",
      "training loss:  0.5014653662840526 traing_acc:  0.7979166666666667\n",
      "training loss:  0.5157882591088613 traing_acc:  0.78125\n",
      "training loss:  0.5193982462088267 traing_acc:  0.7885416666666667\n",
      "training loss:  0.5267113248507181 traing_acc:  0.771875\n",
      "training loss:  0.525606119632721 traing_acc:  0.765625\n",
      "training loss:  0.517709751923879 traing_acc:  0.7885416666666667\n",
      "training loss:  0.5213216205437978 traing_acc:  0.7791666666666667\n",
      "training loss:  0.5207842091719309 traing_acc:  0.7729166666666667\n",
      "training loss:  0.5110360105832418 traing_acc:  0.7979166666666667\n",
      "training loss:  0.5146743853886923 traing_acc:  0.7947916666666667\n",
      "training loss:  0.5048057893911998 traing_acc:  0.80625\n",
      "training loss:  0.5269121964772542 traing_acc:  0.7802083333333333\n",
      "training loss:  0.4952063918113708 traing_acc:  0.8072916666666666\n",
      "training loss:  0.5059303065141042 traing_acc:  0.796875\n",
      "training loss:  0.5055783092975616 traing_acc:  0.7885416666666667\n",
      "training loss:  0.48015286326408385 traing_acc:  0.8291666666666667\n",
      "training loss:  0.5109694401423136 traing_acc:  0.7916666666666666\n",
      "training loss:  0.5035351554552714 traing_acc:  0.7989583333333333\n",
      "training loss:  0.49497511188189186 traing_acc:  0.8208333333333333\n",
      "training loss:  0.49977753361066185 traing_acc:  0.8072916666666666\n",
      "training loss:  0.49323281049728396 traing_acc:  0.8114583333333333\n",
      "training loss:  0.5077597916126251 traing_acc:  0.7916666666666666\n",
      "training loss:  0.5349898497263591 traing_acc:  0.7614583333333333\n",
      "training loss:  0.5033699234326681 traing_acc:  0.8\n",
      "training loss:  0.4967572073141734 traing_acc:  0.7927083333333333\n",
      "training loss:  0.501881625254949 traing_acc:  0.796875\n",
      "training loss:  0.49514334797859194 traing_acc:  0.8072916666666666\n",
      "training loss:  0.504419062534968 traing_acc:  0.803125\n",
      "training loss:  0.5045570214589437 traing_acc:  0.7864583333333334\n",
      "training loss:  0.4989688833554586 traing_acc:  0.8041666666666667\n",
      "training loss:  0.4884715497493744 traing_acc:  0.8135416666666667\n",
      "training loss:  0.487106720606486 traing_acc:  0.81875\n",
      "training loss:  0.47406346201896665 traing_acc:  0.83125\n",
      "training loss:  0.5016361574331919 traing_acc:  0.8\n",
      "training loss:  0.48377980987230934 traing_acc:  0.8229166666666666\n",
      "training loss:  0.4884215851624807 traing_acc:  0.8166666666666667\n",
      "training loss:  0.47542195916175845 traing_acc:  0.821875\n",
      "training loss:  0.49690123200416564 traing_acc:  0.8104166666666667\n",
      "training loss:  0.4802045742670695 traing_acc:  0.8260416666666667\n",
      "training loss:  0.5026316146055857 traing_acc:  0.8\n",
      "training loss:  0.4865322172641754 traing_acc:  0.8177083333333334\n",
      "training loss:  0.5056304017702739 traing_acc:  0.796875\n",
      "training loss:  0.5050040245056152 traing_acc:  0.8\n",
      "training loss:  0.5020344813664754 traing_acc:  0.8041666666666667\n",
      "training loss:  0.4839974582195282 traing_acc:  0.828125\n",
      "training loss:  0.4881819268067678 traing_acc:  0.8135416666666667\n",
      "training loss:  0.4924255987008413 traing_acc:  0.8145833333333333\n",
      "training loss:  0.4624796787897746 traing_acc:  0.8416666666666667\n",
      "training loss:  0.48465312520662945 traing_acc:  0.8197916666666667\n",
      "training loss:  0.48932293653488157 traing_acc:  0.8229166666666666\n",
      "training loss:  0.49979925751686094 traing_acc:  0.8052083333333333\n",
      "training loss:  0.4894748111565908 traing_acc:  0.809375\n",
      "training loss:  0.4808084726333618 traing_acc:  0.8322916666666667\n",
      "training loss:  0.5038061360518138 traing_acc:  0.7916666666666666\n",
      "training loss:  0.48344956437746683 traing_acc:  0.825\n",
      "training loss:  0.49382214148839315 traing_acc:  0.809375\n",
      "training loss:  0.4868993580341339 traing_acc:  0.815625\n",
      "training loss:  0.4862977206707001 traing_acc:  0.8229166666666666\n",
      "training loss:  0.5064797302087148 traing_acc:  0.8\n",
      "training loss:  0.4818359871705373 traing_acc:  0.8177083333333334\n",
      "training loss:  0.4840936899185181 traing_acc:  0.8145833333333333\n",
      "training loss:  0.47938142021497093 traing_acc:  0.8229166666666666\n",
      "training loss:  0.4739385485649109 traing_acc:  0.8395833333333333\n",
      "training loss:  0.49831305543581644 traing_acc:  0.7979166666666667\n",
      "training loss:  0.5260681053002675 traing_acc:  0.7666666666666667\n",
      "training loss:  0.49235020677248637 traing_acc:  0.8125\n",
      "training loss:  0.5080872019131978 traing_acc:  0.7979166666666667\n",
      "training loss:  0.5038617670536041 traing_acc:  0.7979166666666667\n",
      "training loss:  0.49118277430534363 traing_acc:  0.8166666666666667\n",
      "training loss:  0.487795490026474 traing_acc:  0.8125\n",
      "training loss:  0.47573700348536174 traing_acc:  0.8302083333333333\n",
      "training loss:  0.4943717320760091 traing_acc:  0.8083333333333333\n",
      "training loss:  0.49049131671587626 traing_acc:  0.8125\n",
      "training loss:  0.4840333600838979 traing_acc:  0.821875\n",
      "training loss:  0.489002517859141 traing_acc:  0.8125\n",
      "training loss:  0.48786022067070006 traing_acc:  0.8177083333333334\n",
      "training loss:  0.4751591463883718 traing_acc:  0.83125\n",
      "training loss:  0.469474063316981 traing_acc:  0.834375\n",
      "training loss:  0.48968170285224916 traing_acc:  0.8104166666666667\n",
      "training loss:  0.48322427868843076 traing_acc:  0.8197916666666667\n",
      "training loss:  0.4693298240502675 traing_acc:  0.8354166666666667\n",
      "training loss:  0.4875623901685079 traing_acc:  0.8145833333333333\n",
      "training loss:  0.4751336415608724 traing_acc:  0.8354166666666667\n",
      "training loss:  0.48536452651023865 traing_acc:  0.8166666666666667\n",
      "training loss:  0.48148938616116843 traing_acc:  0.825\n",
      "training loss:  0.4741554121176402 traing_acc:  0.825\n",
      "training loss:  0.4936302026112874 traing_acc:  0.8041666666666667\n",
      "training loss:  0.4649824559688568 traing_acc:  0.8385416666666666\n",
      "training loss:  0.4890118777751923 traing_acc:  0.8020833333333334\n",
      "training loss:  0.4973719378312429 traing_acc:  0.8052083333333333\n",
      "training loss:  0.48719072540601094 traing_acc:  0.8197916666666667\n",
      "training loss:  0.4672365128993988 traing_acc:  0.8385416666666666\n",
      "training loss:  0.4747504274050395 traing_acc:  0.8322916666666667\n",
      "training loss:  0.46729849179585775 traing_acc:  0.8458333333333333\n",
      "training loss:  0.4745807150999705 traing_acc:  0.8239583333333333\n",
      "training loss:  0.4831323762734731 traing_acc:  0.8260416666666667\n",
      "training loss:  0.47688177824020384 traing_acc:  0.828125\n",
      "training loss:  0.48055424094200133 traing_acc:  0.8260416666666667\n",
      "training loss:  0.4869648357232412 traing_acc:  0.8197916666666667\n",
      "training loss:  0.47547487417856854 traing_acc:  0.8333333333333334\n",
      "training loss:  0.4848877489566803 traing_acc:  0.8260416666666667\n",
      "training loss:  0.49371949235598245 traing_acc:  0.8041666666666667\n",
      "training loss:  0.53941663702329 traing_acc:  0.7583333333333333\n",
      "training loss:  0.48902867635091146 traing_acc:  0.821875\n",
      "training loss:  0.5030849675337473 traing_acc:  0.8052083333333333\n",
      "training loss:  0.4811803678671519 traing_acc:  0.8239583333333333\n",
      "training loss:  0.4906604766845703 traing_acc:  0.815625\n",
      "training loss:  0.4783314903577169 traing_acc:  0.83125\n",
      "training loss:  0.4657338301340739 traing_acc:  0.8364583333333333\n",
      "training loss:  0.48062389095624286 traing_acc:  0.821875\n",
      "training loss:  0.46104636589686077 traing_acc:  0.8458333333333333\n",
      "training loss:  0.4535328447818756 traing_acc:  0.859375\n",
      "training loss:  0.48036082784334816 traing_acc:  0.8208333333333333\n",
      "training loss:  0.4882724523544312 traing_acc:  0.8145833333333333\n",
      "training loss:  0.47659886280695596 traing_acc:  0.825\n",
      "training loss:  0.4601621131102244 traing_acc:  0.8479166666666667\n",
      "training loss:  0.487326588233312 traing_acc:  0.8291666666666667\n",
      "training loss:  0.4798868159453074 traing_acc:  0.828125\n",
      "training loss:  0.47553306818008423 traing_acc:  0.8270833333333333\n",
      "training loss:  0.4619763414065043 traing_acc:  0.8479166666666667\n",
      "training loss:  0.47047979235649107 traing_acc:  0.8375\n",
      "training loss:  0.46428893009821576 traing_acc:  0.8416666666666667\n",
      "training loss:  0.4793135682741801 traing_acc:  0.8208333333333333\n",
      "training loss:  0.490562778711319 traing_acc:  0.8125\n",
      "training loss:  0.4761418839295705 traing_acc:  0.8270833333333333\n",
      "training loss:  0.46501266956329346 traing_acc:  0.8427083333333333\n",
      "training loss:  0.472432670990626 traing_acc:  0.834375\n",
      "training loss:  0.47431642810503644 traing_acc:  0.8322916666666667\n",
      "training loss:  0.4610238035519918 traing_acc:  0.8458333333333333\n",
      "training loss:  0.48537158171335854 traing_acc:  0.8125\n",
      "training loss:  0.4811452229817708 traing_acc:  0.821875\n",
      "training loss:  0.45607894062995913 traing_acc:  0.8520833333333333\n",
      "training loss:  0.4838391562302907 traing_acc:  0.8197916666666667\n",
      "training loss:  0.48149421215057375 traing_acc:  0.828125\n",
      "training loss:  0.45932099024454753 traing_acc:  0.8458333333333333\n",
      "training loss:  0.49049907525380454 traing_acc:  0.8104166666666667\n",
      "training loss:  0.47229706645011904 traing_acc:  0.8260416666666667\n",
      "training loss:  0.4751861174901327 traing_acc:  0.8333333333333334\n",
      "training loss:  0.46856714487075807 traing_acc:  0.84375\n",
      "training loss:  0.46992081999778745 traing_acc:  0.8385416666666666\n",
      "training loss:  0.4659575939178467 traing_acc:  0.8416666666666667\n",
      "training loss:  0.4612218618392944 traing_acc:  0.8447916666666667\n",
      "training loss:  0.45814323822657266 traing_acc:  0.8458333333333333\n",
      "training loss:  0.48266224265098573 traing_acc:  0.815625\n",
      "training loss:  0.46023223797480267 traing_acc:  0.85\n",
      "training loss:  0.4659092863400777 traing_acc:  0.84375\n",
      "training loss:  0.45653242667516075 traing_acc:  0.8520833333333333\n",
      "training loss:  0.47932464480400083 traing_acc:  0.8197916666666667\n",
      "training loss:  0.46594916184743246 traing_acc:  0.84375\n",
      "training loss:  0.48510603308677674 traing_acc:  0.821875\n",
      "training loss:  0.4567383567492167 traing_acc:  0.85\n",
      "training loss:  0.45900211135546365 traing_acc:  0.8447916666666667\n",
      "training loss:  0.47480313579241434 traing_acc:  0.8322916666666667\n",
      "training loss:  0.46515857179959613 traing_acc:  0.84375\n",
      "training loss:  0.4659808079401652 traing_acc:  0.8458333333333333\n",
      "training loss:  0.48552680214246113 traing_acc:  0.8166666666666667\n",
      "training loss:  0.47964632709821065 traing_acc:  0.825\n",
      "training loss:  0.4636230091253916 traing_acc:  0.8364583333333333\n",
      "training loss:  0.46245352029800413 traing_acc:  0.8427083333333333\n",
      "training loss:  0.47412346402804056 traing_acc:  0.8322916666666667\n",
      "training loss:  0.4790945549805959 traing_acc:  0.8270833333333333\n",
      "training loss:  0.4685480753580729 traing_acc:  0.840625\n",
      "training loss:  0.4783827424049377 traing_acc:  0.8354166666666667\n",
      "training loss:  0.4698337773482005 traing_acc:  0.828125\n",
      "training loss:  0.46750643452008567 traing_acc:  0.8385416666666666\n",
      "training loss:  0.4508409043153127 traing_acc:  0.85625\n",
      "training loss:  0.4701556901137034 traing_acc:  0.834375\n",
      "training loss:  0.46551037828127545 traing_acc:  0.8416666666666667\n",
      "training loss:  0.4570517897605896 traing_acc:  0.8572916666666667\n",
      "training loss:  0.4668524622917175 traing_acc:  0.8375\n",
      "training loss:  0.4585017224152883 traing_acc:  0.84375\n",
      "training loss:  0.4547754307587942 traing_acc:  0.85\n",
      "training loss:  0.4564885755379995 traing_acc:  0.8520833333333333\n",
      "training loss:  0.47885040442148846 traing_acc:  0.8260416666666667\n",
      "training loss:  0.45253633459409076 traing_acc:  0.8552083333333333\n",
      "training loss:  0.472108926375707 traing_acc:  0.83125\n",
      "training loss:  0.4704324841499329 traing_acc:  0.8364583333333333\n",
      "training loss:  0.46506837805112206 traing_acc:  0.8416666666666667\n",
      "training loss:  0.46628512342770895 traing_acc:  0.8416666666666667\n",
      "training loss:  0.46416902740796406 traing_acc:  0.8447916666666667\n",
      "training loss:  0.4621705214182536 traing_acc:  0.8416666666666667\n",
      "training loss:  0.4607813636461894 traing_acc:  0.8489583333333334\n",
      "training loss:  0.46234090924263 traing_acc:  0.8520833333333333\n",
      "training loss:  0.4709048946698507 traing_acc:  0.8364583333333333\n",
      "training loss:  0.47975533405939735 traing_acc:  0.8302083333333333\n",
      "training loss:  0.4617258628209432 traing_acc:  0.84375\n",
      "training loss:  0.47117565870285033 traing_acc:  0.8385416666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  0.46606908837954203 traing_acc:  0.8395833333333333\n",
      "training loss:  0.4662464718023936 traing_acc:  0.840625\n",
      "training loss:  0.46157235304514566 traing_acc:  0.840625\n",
      "training loss:  0.46313853065172833 traing_acc:  0.8427083333333333\n",
      "training loss:  0.4538256625334422 traing_acc:  0.85\n",
      "training loss:  0.46000654101371763 traing_acc:  0.8520833333333333\n",
      "training loss:  0.46483010053634644 traing_acc:  0.8447916666666667\n",
      "training loss:  0.4976458489894867 traing_acc:  0.803125\n",
      "training loss:  0.44505734244982403 traing_acc:  0.86875\n",
      "training loss:  0.4628280162811279 traing_acc:  0.840625\n",
      "training loss:  0.45063533782958987 traing_acc:  0.8645833333333334\n",
      "training loss:  0.4635924756526947 traing_acc:  0.8395833333333333\n",
      "training loss:  0.4642222026983897 traing_acc:  0.8395833333333333\n",
      "training loss:  0.45740951895713805 traing_acc:  0.8489583333333334\n",
      "training loss:  0.4462892532348633 traing_acc:  0.8625\n",
      "training loss:  0.4630234996477763 traing_acc:  0.8427083333333333\n",
      "training loss:  0.46793645024299624 traing_acc:  0.828125\n",
      "training loss:  0.45936224460601804 traing_acc:  0.8489583333333334\n",
      "training loss:  0.47989139159520466 traing_acc:  0.8270833333333333\n",
      "training loss:  0.4562446753184001 traing_acc:  0.8489583333333334\n",
      "training loss:  0.4576548953851064 traing_acc:  0.8489583333333334\n",
      "training loss:  0.44665184219678244 traing_acc:  0.8604166666666667\n",
      "training loss:  0.4554320712884267 traing_acc:  0.8552083333333333\n",
      "training loss:  0.471876068909963 traing_acc:  0.8354166666666667\n",
      "training loss:  0.46462140083312986 traing_acc:  0.840625\n",
      "training loss:  0.4763595958550771 traing_acc:  0.8333333333333334\n",
      "training loss:  0.4723501225312551 traing_acc:  0.8354166666666667\n",
      "training loss:  0.4637778023878733 traing_acc:  0.8427083333333333\n",
      "training loss:  0.45823503732681276 traing_acc:  0.8479166666666667\n",
      "training loss:  0.4495275437831879 traing_acc:  0.8604166666666667\n",
      "training loss:  0.4614021142323812 traing_acc:  0.8458333333333333\n",
      "training loss:  0.46161843140920006 traing_acc:  0.8458333333333333\n",
      "training loss:  0.4556735157966614 traing_acc:  0.8447916666666667\n",
      "training loss:  0.48959533174832665 traing_acc:  0.81875\n",
      "training loss:  0.44164297183354695 traing_acc:  0.8666666666666667\n",
      "training loss:  0.4431715667247772 traing_acc:  0.8677083333333333\n",
      "training loss:  0.45596330960591636 traing_acc:  0.8541666666666666\n",
      "training loss:  0.46265525221824644 traing_acc:  0.8416666666666667\n",
      "training loss:  0.4397895435492198 traing_acc:  0.8677083333333333\n",
      "training loss:  0.47028535008430483 traing_acc:  0.834375\n",
      "training loss:  0.4532031357288361 traing_acc:  0.8572916666666667\n",
      "training loss:  0.4513687868913015 traing_acc:  0.8583333333333333\n",
      "training loss:  0.4613647758960724 traing_acc:  0.8416666666666667\n",
      "training loss:  0.4534051259358724 traing_acc:  0.8541666666666666\n",
      "training loss:  0.461325458685557 traing_acc:  0.8354166666666667\n",
      "training loss:  0.46158474882443745 traing_acc:  0.8458333333333333\n",
      "training loss:  0.4613689382870992 traing_acc:  0.8427083333333333\n",
      "training loss:  0.44620719154675803 traing_acc:  0.8666666666666667\n",
      "training loss:  0.44381156762441 traing_acc:  0.8625\n",
      "training loss:  0.4527932564417521 traing_acc:  0.8583333333333333\n",
      "training loss:  0.45848138531049093 traing_acc:  0.846875\n",
      "training loss:  0.4280988315741221 traing_acc:  0.88125\n",
      "training loss:  0.45324421525001524 traing_acc:  0.8541666666666666\n",
      "training loss:  0.4586352547009786 traing_acc:  0.8541666666666666\n",
      "training loss:  0.45083274245262145 traing_acc:  0.8520833333333333\n",
      "training loss:  0.4565690577030182 traing_acc:  0.8510416666666667\n",
      "training loss:  0.4707308034102122 traing_acc:  0.8364583333333333\n",
      "training loss:  0.47513734300931293 traing_acc:  0.828125\n",
      "training loss:  0.4587340195973714 traing_acc:  0.8385416666666666\n",
      "training loss:  0.4535134454568227 traing_acc:  0.8572916666666667\n",
      "training loss:  0.46424171527226765 traing_acc:  0.8510416666666667\n",
      "training loss:  0.456205681959788 traing_acc:  0.85\n",
      "training loss:  0.4543575922648112 traing_acc:  0.853125\n",
      "training loss:  0.4737253685792287 traing_acc:  0.8354166666666667\n",
      "training loss:  0.4608156144618988 traing_acc:  0.846875\n",
      "training loss:  0.4501121381918589 traing_acc:  0.8604166666666667\n",
      "training loss:  0.439035028219223 traing_acc:  0.8729166666666667\n",
      "training loss:  0.4545640389124552 traing_acc:  0.853125\n",
      "training loss:  0.4314542531967163 traing_acc:  0.8822916666666667\n",
      "training loss:  0.4482332428296407 traing_acc:  0.8604166666666667\n",
      "training loss:  0.4541527966658274 traing_acc:  0.8572916666666667\n",
      "training loss:  0.4433891375859578 traing_acc:  0.8645833333333334\n",
      "training loss:  0.4469563821951548 traing_acc:  0.85625\n",
      "training loss:  0.4399040480454763 traing_acc:  0.8677083333333333\n",
      "training loss:  0.4440413256486257 traing_acc:  0.8625\n",
      "training loss:  0.46268497308095297 traing_acc:  0.8447916666666667\n",
      "training loss:  0.45030292868614197 traing_acc:  0.8583333333333333\n",
      "training loss:  0.4547033985455831 traing_acc:  0.8479166666666667\n",
      "training loss:  0.4528732260068258 traing_acc:  0.85625\n",
      "training loss:  0.4450866242249807 traing_acc:  0.85625\n",
      "training loss:  0.4500071903069814 traing_acc:  0.8520833333333333\n",
      "training loss:  0.45050768852233886 traing_acc:  0.8604166666666667\n",
      "training loss:  0.46438570817311603 traing_acc:  0.8395833333333333\n",
      "training loss:  0.45128962596257527 traing_acc:  0.8541666666666666\n",
      "training loss:  0.4595756113529205 traing_acc:  0.8447916666666667\n",
      "training loss:  0.45628241101900735 traing_acc:  0.8520833333333333\n",
      "training loss:  0.44523834983507793 traing_acc:  0.86875\n",
      "training loss:  0.4563913742701213 traing_acc:  0.8489583333333334\n",
      "training loss:  0.4630812962849935 traing_acc:  0.8427083333333333\n",
      "training loss:  0.4439197242259979 traing_acc:  0.8645833333333334\n",
      "training loss:  0.4545689264933268 traing_acc:  0.8541666666666666\n",
      "training loss:  0.4498125155766805 traing_acc:  0.85625\n",
      "training loss:  0.45271264712015785 traing_acc:  0.85\n",
      "training loss:  0.44649903575579325 traing_acc:  0.8645833333333334\n",
      "training loss:  0.4373217225074768 traing_acc:  0.8677083333333333\n",
      "training loss:  0.43582119743029274 traing_acc:  0.875\n",
      "training loss:  0.4643623868624369 traing_acc:  0.8416666666666667\n",
      "training loss:  0.46674437721570333 traing_acc:  0.8385416666666666\n",
      "training loss:  0.4550140897432963 traing_acc:  0.8541666666666666\n",
      "training loss:  0.44089177846908567 traing_acc:  0.8708333333333333\n",
      "training loss:  0.4436043679714203 traing_acc:  0.8645833333333334\n",
      "training loss:  0.4432352900505066 traing_acc:  0.8645833333333334\n",
      "training loss:  0.4484538833300273 traing_acc:  0.8666666666666667\n",
      "training loss:  0.45232622424761454 traing_acc:  0.8614583333333333\n",
      "training loss:  0.45798452695210773 traing_acc:  0.8510416666666667\n",
      "training loss:  0.4469330588976542 traing_acc:  0.85625\n",
      "training loss:  0.4530684967835744 traing_acc:  0.8572916666666667\n",
      "training loss:  0.43971779743830364 traing_acc:  0.8614583333333333\n",
      "training loss:  0.4591876844565074 traing_acc:  0.8416666666666667\n",
      "training loss:  0.4424056669076284 traing_acc:  0.86875\n",
      "training loss:  0.4451372583707174 traing_acc:  0.8645833333333334\n",
      "training loss:  0.45808627009391784 traing_acc:  0.8479166666666667\n",
      "training loss:  0.4561472018559774 traing_acc:  0.8458333333333333\n",
      "training loss:  0.45346354444821674 traing_acc:  0.853125\n",
      "training loss:  0.4493588745594025 traing_acc:  0.8583333333333333\n",
      "training loss:  0.4356168250242869 traing_acc:  0.8708333333333333\n",
      "training loss:  0.44757855534553526 traing_acc:  0.8572916666666667\n",
      "training loss:  0.44598520000775654 traing_acc:  0.8614583333333333\n",
      "training loss:  0.4468825042247772 traing_acc:  0.859375\n",
      "training loss:  0.4492792010307312 traing_acc:  0.8552083333333333\n",
      "training loss:  0.4508988658587138 traing_acc:  0.8552083333333333\n",
      "training loss:  0.46311445434888204 traing_acc:  0.8427083333333333\n",
      "training loss:  0.4261220415433248 traing_acc:  0.8791666666666667\n",
      "training loss:  0.4503005504608154 traing_acc:  0.8572916666666667\n"
     ]
    }
   ],
   "source": [
    "##### first download the dataset and unzipped the image folders ## done\n",
    "\n",
    "# set parameters (learning rate, batch size, number of epochs...)\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "logstep = int(1000 // batch_size)\n",
    "num_workers = 0\n",
    "\n",
    "# create dataloader for training dataset\n",
    "train_loader = datatorch.DataLoader(dataset=train_dataset, \n",
    "                         shuffle=True, \n",
    "                         batch_size=batch_size)\n",
    "\n",
    "\n",
    "# create network model\n",
    "# source: https://wtfleming.github.io/2020/04/12/pytorch-cats-vs-dogs-part-3/\n",
    "model.fc = nn.Sequential(nn.Linear(model.fc.in_features,512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(512, 2))\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cuda:0\")\n",
    "model =model.to(device)\n",
    "# create optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[500,1000,1500], gamma=0.5)\n",
    "\n",
    "training_loss_vec = []\n",
    "training_accuracy_vec = []\n",
    "\n",
    "# loop over epochs\n",
    "model.train()\n",
    "for e in range(epochs):\n",
    "    training_loss = 0.\n",
    "    training_accuracy = 0.\n",
    "    for n, (x,y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        #print(x.shape)\n",
    "        # call optimizer.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        # compute predictions using model\n",
    "        y_pred =  model(x)\n",
    "        # compute loss\n",
    "        loss = criterion(y_pred, y)\n",
    "        # run backward method\n",
    "        loss.backward()\n",
    "        # run optimizer step\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # logging (optional)\n",
    "        training_loss += loss.item()\n",
    "        y_pred_idx = torch.max(y_pred.detach().cpu(),dim=1)[1]\n",
    "        training_accuracy += torch.mean((y_pred_idx == y.cpu()).float()).item()\n",
    "        if (n+1) % logstep == 0: \n",
    "            training_loss_vec.append(training_loss/logstep)\n",
    "            training_accuracy_vec.append(training_accuracy/logstep)\n",
    "            print('training loss: ', training_loss/logstep,'traing_acc: ',training_accuracy/logstep)\n",
    "            training_loss, training_accuracy = 0.,0.\n",
    "   \n",
    "\n",
    "# create dataloader for test dataset\n",
    "# get predictions, save the file and submit it to kaggle (see the kaggle page for info on the submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(logstep*np.arange(1,1+len(training_loss_vec)),np.array(training_loss_vec))\n",
    "plt.ylabel(\"loss criterion\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.show()\n",
    "plt.plot(logstep*np.arange(1,1+len(training_accuracy_vec)),np.array(training_accuracy_vec))\n",
    "plt.ylabel(\"training accuracy\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.show()\n",
    "print(max(training_accuracy_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/jaeboklee/pytorch-cat-vs-dog\n",
    "testloader = datatorch.DataLoader(test_dataset, batch_size = 1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "fn_list = []\n",
    "pred_list = []\n",
    "i = 0\n",
    "for x, fn in testloader:\n",
    "    with torch.no_grad():\n",
    "        x = x.to(device)\n",
    "        output = model(x)\n",
    "        \n",
    "        \n",
    "        pred = torch.argmax(output, dim=1)\n",
    "       \n",
    "        fn_list.append(fn.item())\n",
    "        pred_list += [p.item() for p in pred]\n",
    "        \n",
    "\n",
    "submission = pd.DataFrame({\"id\":fn_list, \"label\":pred_list})\n",
    "submission.to_csv('submission7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fn_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model with 88.8% accuracy\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            nn.Flatten(),\n",
    "            torch.nn.Linear(9216, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 2),\n",
    "            torch.nn.Sigmoid()\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.1",
    "jupytext_version": "1.2.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
