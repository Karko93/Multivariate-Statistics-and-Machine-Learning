{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Statistik und Machine Learning: Assignment 5\n",
    "\n",
    "In this exercise we will use unsupervised methods for clustering, in this case instead of having $X$ and $Y$ pairs at train time, we *only* have the input data $X$ at train time.\n",
    "\n",
    "We will work with 3 popular methods: K-means, Spectral Clustering and Mean-shift.\n",
    "\n",
    "To get familiar with their adavantages and disanvantages we will use the 3 methods with 3 different datasets:\n",
    "\n",
    "- spiral\n",
    "- blobs\n",
    "- hand-written digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1 -- Spectral Clustering (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "data = np.load(\"spiral.npz\")\n",
    "x = data[\"x\"]\n",
    "y = data[\"y\"]\n",
    "\n",
    "plt.scatter(x[:,0],x[:,1],c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Adjacency matrix\n",
    "implement the function 'build_adjacency_matrix' which receives as input the array $x$ and creates and adjacency matrix using the RBF kernel:\n",
    "$$a_{ij} = e^{(-\\gamma \\cdot d(x_i,x_j)^2)}$$\n",
    "where $d(\\cdot,\\cdot))$ represents the euclidian distance.\n",
    "\n",
    "hint: try to use the numpy array operations and avoid for loops to speed up the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adjacency_matrix(x,gamma):\n",
    "    \"\"\"\n",
    "        x: numpy array shape = [N samples, input dimension]\n",
    "        gamma: parameter for the RBF kernel\n",
    "    \n",
    "        return the adjacency matrix A (shape =  [N samples,N samples])\n",
    "    \"\"\"\n",
    "    \n",
    "    return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "A = build_adjacency_matrix(x,gamma=None)\n",
    "# visualize matrix A\n",
    "plt.matshow(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. sklearn spectral clustering\n",
    "\n",
    "validate your adjacency matrix using the spectral clustering framework of sklearn. choose as affinity parameter the option 'precomputed'. What is a good value for $\\gamma$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = # spectral clustering sklearn class with affinity precomputed\n",
    "y_pred = sc.fit_predict(A)\n",
    "plt.scatter(x[:,0],x[:,1],c=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Affinity options\n",
    "Try now to use as affinity option 'nearest_neighbors' which builds a graph using the input data. What is a good value for 'n_neighbors' in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = # spectral clustering sklearn class with affinity nearest neigbors\n",
    "y_pred = sc.fit_predict(x) \n",
    "plt.scatter(x[:,0],x[:,1],c=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 2 -- K-means (2 point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Blobs dataset\n",
    "\n",
    "Using the KMeans class, cluster the points in the blobs dataset. You may explore the different configurations such as initalization (random or k-means++), n_init.\n",
    "\n",
    "Choosing the number of n_clusters without extra information is not trivial. For blobs, we don't have any labels. Which configurations are be thest for this dataset? How many n_custers would you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.genfromtxt('blobs.csv', delimiter=',')\n",
    "\n",
    "model = KMeans(...)\n",
    "\n",
    "y_hat = model.fit_predict(x)\n",
    "\n",
    "plt.scatter(x[:,0],x[:,1],c=y_hat, marker='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Spiral dataset\n",
    "\n",
    "Try to use the KMeans to cluster the Spiral dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"spiral.npz\")['x']\n",
    "\n",
    "model = KMeans(...)\n",
    "\n",
    "y_hat = model.fit_predict(x)\n",
    "\n",
    "plt.scatter(x[:,0],x[:,1],c=y_hat, marker='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it work? Please explain your answer, which assumptions required for kmeans? would feature augmentation (as we did in regression) help here? Just explain what you would do, you are not required to implement anything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 3 -- Mean Shift Clustering (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the function ``ml_meanshift`` that performs the mean shift algorithm. The function takes 3 arguments:\n",
    " \n",
    "* input data: sample points in a N-by-2 matrix (number of rows is the number of samples, dimensionality of the input data will always be 2 for this exercise)\n",
    "* the kernel bandwidth $h$\n",
    "* the stopping threshold $\\vartheta$\n",
    "\n",
    "\n",
    "It should return two values.\n",
    "* cluster indexes: a column vector with N rows, specifying the cluster index for each sample\n",
    "* cluster modes: a M-by-2 matrix, returning the cluster modes (the points with the highest density) for each cluster (where M is the number of clusters)\n",
    "    \n",
    "For this task, use the Epanechnikov kernel. Luckily all terms before the sum cancel out in the mean shift formula, leading to\n",
    "\n",
    "$$\\mathbf{q}_{t+1} = \\frac{\n",
    "            \\sum_{i=1}^N \\mathbf{x}_i \n",
    "            \\max\\left(0, 1 - \\frac{\\|\\mathbf{q}_t - \\mathbf{x}_i\\|^2}{h^2} \\right)\n",
    "        } {\n",
    "            \\sum_{i=1}^N \n",
    "            \\max\\left(0, 1 - \\frac{\\|\\mathbf{q}_t - \\mathbf{x}_i\\|^2}{h^2} \\right)\n",
    "        }$$\n",
    "\n",
    "    \n",
    "Start the mean shift procedure at each point and iterate until $\\|\\mathbf{q}_{t}-\\mathbf{q}_{t-1}\\| < \\vartheta$ where $\\vartheta$ is the threshold passed to the function. Additionally also count the iterations and add it as condtion so the loop does not run infinitely. You can use $200$ as the maximum value of iteration.\n",
    "\n",
    "When the iteration stopped, decide if a cluster mode already exists that is closer than $\\frac{h}{5}$. If yes, assign the point that you started at to this cluster. Otherwise, create a new cluster and assign the point to the new cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports you need for the exercises\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt    \n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "from numpy import linalg as la\n",
    "import numpy.matlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # DO NOT MODIFY\n",
    "def visualize_kmeans(data,idx,centers,updated=None):\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.scatter(data[:,0],data[:,1],marker='.', c=idx)\n",
    "    ax.plot(centers[:,0],centers[:,1],'+',color='r',markersize=15,mew=2)\n",
    "    plt.show()\n",
    "def test_meanshift():\n",
    "    data = np.genfromtxt('blobs.csv', delimiter=',')\n",
    "    idx, centers = ml_meanshift(data,4,0.001)\n",
    "    \n",
    "    centers_2 = np.array(centers)\n",
    "    \n",
    "    visualize_kmeans(data=data,idx=idx,centers=centers_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_meanshift(data,h,theta):\n",
    "    # ml_meanshift returns cluster indices and modes from computed with meanshift algorithm\n",
    "\n",
    "    # initialization\n",
    "    # modes\n",
    "\n",
    "    #initialize index variable for data points\n",
    "\n",
    "\n",
    "    #s = number of data points\n",
    "\n",
    "\n",
    "    for i in range(s):\n",
    "        \n",
    "        #initialize starting q0 and q1 condition\n",
    "        \n",
    "\n",
    "        #iteration initilization\n",
    "        it = 0\n",
    "\n",
    "        #iterate until ||q_t - q_t-1|| < theta and it<200\n",
    "        while()\n",
    "        \n",
    "            #update break criterion values\n",
    "\n",
    "            #compute q_t+1\n",
    "\n",
    "            #update iteration\n",
    "            it = it+1\n",
    "\n",
    "        #check for clusters in the vicinity\n",
    "        #1st condition: if mode is not empty\n",
    "        #2nd: if a cluster mode exists closer than h/5\n",
    "        #else create a new cluster\n",
    "        if():\n",
    "\n",
    "        else:\n",
    "            \n",
    "\n",
    "    return index, modes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    " test_meanshift()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 4 -- Handwritten digits (2 points)\n",
    "\n",
    "Now we will wokrk with hand-written digits images that can be clustered. Let's first load the dataset and see some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from string import ascii_uppercase\n",
    "x, y = load_digits(return_X_y=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "\n",
    "x = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(x,y=None, max_n = 8, random=True):\n",
    "    x = scaler.inverse_transform(x)\n",
    "    if random:\n",
    "        samples = np.random.choice(x.shape[0], max_n,replace=False)\n",
    "    else:\n",
    "        samples = range(max_n)\n",
    "    for i, index in enumerate(samples):\n",
    "        \n",
    "        plt.subplot(2, max_n//2, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(x[index].reshape(8,8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        if y is not None:\n",
    "            plt.title(f'cluster {ascii_uppercase[y[index]]}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(x, y, random=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that we name the clusters A - H, in the reference data cluster A corresponds to digit 0, B to digit 1 and so on. But in a prediction using any method will just create clusters with out necesarrily matching the original correspondance.\n",
    "\n",
    "Visualizing the complete dataset of images is challenging, for such purpose we will use T-SNE to visualize on a 2-dim plot. Each point in the plot represents one image, and different colors show the digit class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=20, n_iter=300,random_state=1)\n",
    "tsne_results = tsne.fit_transform(x)\n",
    "plt.scatter(tsne_results[:,0], tsne_results[:,1], c=y, cmap='tab10', marker ='.')\n",
    "plt.title('2-dim visualization of the digits datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using kmeans we can cluster the digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=10)\n",
    "\n",
    "y_hat = model.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tsne_results[:,0], tsne_results[:,1], c=y_hat, cmap='tab10', marker='.')\n",
    "plt.title('Kmeans default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(x, y_hat, max_n=8, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Clustering digits\n",
    "Using KMeans, try to find the best configuration, which parameters you consider the most important and why?\n",
    "\n",
    "since computing a quantitative number for performance is more difficult here, you can justify your analysis by commenting the results on the T-SNE visualizayion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MeanShift, SpectralClustering\n",
    "\n",
    "model = KMeans(n_clusters=10, ...)\n",
    "\n",
    "y_hat = model.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tsne_results[:,0], tsne_results[:,1], c=y_hat, cmap='tab10')\n",
    "plt.title('Kmeans improved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. MeanShift and SpectralClustering\n",
    "Try to use MeanShift and SpectralClustering for this dataset, for this exercise you may use the MeanShifi class from sklearn. Does it work? Which method would you prefer in the end KMeans, MeanShift or SpectralClustering? Justify your answwer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MeanShift(...)\n",
    "y_hat = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tsne_results[:,0], tsne_results[:,1], c=y_hat, cmap='tab10')\n",
    "plt.title('Mean Shift default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpectralClustering(...)\n",
    "y_hat = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "plt.scatter(tsne_results[:,0], tsne_results[:,1], c=y_hat, cmap='tab10')\n",
    "plt.title('Spectral Clustering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
